{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuesday, May 21, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on 5/21/24 I googled around for a dataset and found one thru SAMHSA.  it includes everyone, queer and otherwise, but it looks promising.  it's really, really big though, so it's taking a lot of cleaning before I can even evaluate whether it's what I want or not.  maybe i should just define that it is what I want, and then figure out what that is as I clean it.  I definitely think I could make a project out of it, even if it's not the project of my dreams.  this dataset has nearly 3000 columns and it's running VERY slow in Rstudio.  after finding it, I spend several hours going thru the data dictionary to try and eliminate columns.  I got thru the \"self-administered substance use sections,\" and will pick up tomorrow on \"imputed substance use.\"\n",
    "\n",
    "files created:\n",
    "- everything in the potential datasets folder\n",
    "- 2024-05-21_set-up.py\n",
    "- evaluating-columns-in-samhsa-dataset.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capstone Setup\n",
    "\n",
    "# Module Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime, date, time\n",
    "from string import capwords\n",
    "\n",
    "# Working Directory\n",
    "os.getcwd()\n",
    "os.chdir('C:/Users/emily/Git_Stuff/General_Assembly/04_Projects/project-capstone')\n",
    "os.listdir()\n",
    "\n",
    "# Import Data\n",
    "# (This will likely change as my dataset choice changes!)\n",
    "df = pd.read_csv(\n",
    "  './potential_datasets/2024-05-21_download_SAMHSA_NSDUH-2019-DS0001/NSDUH_2019_Tab.txt', \n",
    "  sep = '\\t', low_memory=False)\n",
    "\n",
    "# This thing has 2741 columns!  \n",
    "# I'm going to pair it down by printing out the column names, \n",
    "# copying them to a text file, and then\n",
    "# going through the codebook to see which ones I really need.\n",
    "\n",
    "#print(list(df.columns))\n",
    "# commented out bcz omg.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wednesday, May 22, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today I am continuing to clean that SAMHSA dataset.  I am feeling more and more strongly that I should just make a project out of this, whatever it is, because I am investing so much time into investigating it.  I can always find a more queer-centric dataset later and play with it in my portfolio.\n",
    "\n",
    "~I am going to have multiple scripts today,~ nope, had a power outage instead!\n",
    "\n",
    "files created:\n",
    "- 2024-05-22_continued_column_exploration_of_samhsa_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May 22, 2024\n",
    "\n",
    "# continued column cleaning in SAMHSA dataset\n",
    "# I'm really starting to think that when I get to the bottom of this one, I should just use it\n",
    "\n",
    "# Status: I have gone thru a lot of columns by hand, and noticed some patterns.\n",
    "# Specifically, for rightnow, I have noticed that all variables that only serve to show when another variable has been imputed\n",
    "# start with II.  Therefore, I'm going to use a list comprehension (or similar) to eliminate them all at once.\n",
    "\n",
    "# Here are the remaining column names.  I'm copying them in from evaluating-columns-in-samhsa-dataset.txt, and when I'm done,\n",
    "# I will copy them back.  I am deleting column names in that dataset as I go along.  If I ever need a full list\n",
    "# of the original column names again, I can always pull them again from the original dataset.\n",
    "\n",
    "col_names_1 = ['IRCGRFM', 'IICGRFM', 'II2CGRFM', 'IRSMKLSS30N', 'IISMKLSS30N', 'IRALCFM', 'IIALCFM', 'II2ALCFM', 'IRALCBNG30D', 'IIALCBNG30D', 'IRMJFM', 'IIMJFM', 'II2MJFM', 'IRCOCFM', 'IICOCFM', 'II2COCFM', 'IRCRKFM', 'IICRKFM', 'II2CRKFM', 'IRHERFM', 'IIHERFM', 'II2HERFM', 'IRHALLUC30N', 'IIHALLUC30N', 'IRINHAL30N', 'IIINHAL30N', 'IRMETHAM30N', 'IIMETHAM30N', 'IRPNRNM30FQ', 'IIPNRNM30FQ', 'IRTRQNM30FQ', 'IITRQNM30FQ', 'IRSTMNM30FQ', 'IISTMNM30FQ', 'IRSEDNM30FQ', 'IISEDNM30FQ', 'IRCIGAGE', 'IICIGAGE', 'IRCIGYFU', 'IICIGYFU', 'IRCDUAGE', 'IICDUAGE', 'IRCD2YFU', 'IICD2YFU', 'IRCGRAGE', 'IICGRAGE', 'IRCGRYFU', 'IICGRYFU', 'IRSMKLSSTRY', 'IISMKLSSTRY', 'IRSMKLSSYFU', 'IISMKLSSYFU', 'IRALCAGE', 'IIALCAGE', 'IRALCYFU', 'IIALCYFU', 'IRMJAGE', 'IIMJAGE', 'IRMJYFU', 'IIMJYFU', 'IRCOCAGE', 'IICOCAGE', 'IRCOCYFU', 'IICOCYFU', 'IRCRKAGE', 'IICRKAGE', 'IRCRKYFU', 'IICRKYFU', 'IRHERAGE', 'IIHERAGE', 'IRHERYFU', 'IIHERYFU', 'IRHALLUCAGE', 'IIHALLUCAGE', 'IRHALLUCYFU', 'IIHALLUCYFU', 'IRLSDAGE', 'IILSDAGE', 'IRLSDYFU', 'IILSDYFU', 'IRPCPAGE', 'IIPCPAGE', 'IRPCPYFU', 'IIPCPYFU', 'IRECSTMOAGE', 'IIECSTMOAGE', 'IRECSTMOYFU', 'IIECSTMOYFU', 'IRINHALAGE', 'IIINHALAGE', 'IRINHALYFU', 'IIINHALYFU', 'IRMETHAMAGE', 'IIMETHAMAGE', 'IRMETHAMYFU', 'IIMETHAMYFU', 'IRPNRNMINIT', 'IIPNRNMINIT', 'IRTRQNMINIT', 'IITRQNMINIT', 'IRSTMNMINIT', 'IISTMNMINIT', 'IRSEDNMINIT', 'IISEDNMINIT', 'IRPNRNMYFU', 'IIPNRNMYFU', 'IRPNRNMAGE', 'IIPNRNMAGE', 'IRTRQNMYFU', 'IITRQNMYFU', 'IRTRQNMAGE', 'IITRQNMAGE', 'IRSTMNMYFU', 'IISTMNMYFU', 'IRSTMNMAGE', 'IISTMNMAGE', 'IRSEDNMYFU', 'IISEDNMYFU', 'IRSEDNMAGE', 'IISEDNMAGE', 'CIGFLAG', 'CIGYR', 'CIGMON', 'CGRFLAG', 'CGRYR', 'CGRMON', 'PIPFLAG', 'PIPMON', 'SMKLSSFLAG', 'SMKLSSYR', 'SMKLSSMON', 'TOBFLAG', 'TOBYR', 'TOBMON', 'ALCFLAG', 'ALCYR', 'ALCMON', 'MRJFLAG', 'MRJYR', 'MRJMON', 'COCFLAG', 'COCYR', 'COCMON', 'CRKFLAG', 'CRKYR', 'CRKMON', 'HERFLAG', 'HERYR', 'HERMON', 'HALLUCFLAG', 'HALLUCYR', 'HALLUCMON', 'LSDFLAG', 'LSDYR', 'LSDMON', 'PCPFLAG', 'PCPYR', 'PCPMON', 'ECSTMOFLAG', 'ECSTMOYR', 'ECSTMOMON', 'DAMTFXFLAG', 'DAMTFXYR', 'DAMTFXMON', 'KETMINFLAG', 'KETMINYR', 'KETMINMON', 'SALVIAFLAG', 'SALVIAYR', 'SALVIAMON', 'INHALFLAG', 'INHALYR', 'INHALMON', 'METHAMFLAG', 'METHAMYR', 'METHAMMON', 'PNRANYFLAG', 'PNRANYYR', 'OXYCNANYYR', 'TRQANYFLAG', 'TRQANYYR', 'STMANYFLAG', 'STMANYYR', 'SEDANYFLAG', 'SEDANYYR', 'TQSDANYFLG', 'TQSDANYYR', 'PSYANYFLAG', 'PSYANYYR', 'PNRNMFLAG', 'PNRNMYR', 'PNRNMMON', 'OXYCNNMYR', 'TRQNMFLAG', 'TRQNMYR', 'TRQNMMON', 'STMNMFLAG', 'STMNMYR', 'STMNMMON', 'SEDNMFLAG', 'SEDNMYR', 'SEDNMMON', 'TQSDNMFLAG', 'TQSDNMYR', 'TQSDNMMON', 'PSYCHFLAG', 'PSYCHYR', 'PSYCHMON', 'OPINMYR', 'OPINMMON', 'HERPNRYR', 'ILLFLAG', 'ILLYR', 'ILLMON', 'MJONLYFLAG', 'MJONLYYR', 'MJONLYMON', 'ILLEMFLAG', 'ILLEMYR', 'ILLEMMON', 'CDUFLAG', 'DCIGMON', 'CDCGMO', 'CDNOCGMO', 'BNGDRKMON', 'HVYDRKMON', 'ILTOBALCFG', 'ILTOBALCYR', 'ILTOBALCMN', 'ILLALCMON', 'TOBALCFLG', 'TOBALCYR', 'TOBALCMN', 'ILLANDALC', 'ILLORALC', 'ILLALCFLG', 'PEYOTE2', 'MESC2', 'PSILCY2', 'AMYLNIT2', 'CLEFLU2', 'GAS2', 'GLUE2', 'ETHER2', 'SOLVENT2', 'LGAS2', 'NITOXID2', 'FELTMARKR2', 'SPPAINT2', 'AIRDUSTER2', 'OTHAEROS2', 'HYDCPDAPYU', 'ZOHYANYYR2', 'OXCOPDAPYU', 'TRAMPDAPYU', 'CODEPDAPYU', 'MORPPDAPYU', 'FENTPDAPYU', 'BUPRPDAPYU', 'OXYMPDAPYU', 'DEMEPDAPYU', 'HYDMPDAPYU', 'MTDNPDAPYU', 'PNROTANYR2', 'TRBENZAPYU', 'ALPRPDAPYU', 'LORAPDAPYU', 'CLONPDAPYU', 'DIAZPDAPYU', 'MUSRLXAPYU', 'CYCLPDAPYU', 'SOMAPDAPYU', 'TRQOTANYR2', 'AMMEPDAPYU', 'AMPHETAPYU', 'METHPDAPYU', 'ANOSTMAPYU', 'PROVPDAPYU', 'STMOTANYR2', 'ZOLPPDAPYU', 'ESZOPDAPYU', 'ZALEPDAPYU', 'SVBENZAPYU', 'TRIAPDAPYU', 'TEMAPDAPYU', 'FLURPDAPYU', 'BARBITAPYU', 'SEDOTANYR2', 'BENZOSAPYU', 'HYDCPDPYMU', 'OXCOPDPYMU', 'TRAMPDPYMU', 'CODEPDPYMU', 'MORPPDPYMU', 'FENTPDPYMU', 'BUPRPDPYMU', 'OXYMPDPYMU', 'DEMEPDPYMU', 'HYDMPDPYMU', 'MTDNPDPYMU', 'PNROTHPYMU2', 'TRBENZPYMU', 'ALPRPDPYMU', 'LORAPDPYMU', 'CLONPDPYMU', 'DIAZPDPYMU', 'MUSRLXPYMU', 'CYCLPDPYMU', 'SOMAPDPYMU', 'TRQOTHPYMU2', 'AMMEPDPYMU', 'AMPHETPYMU', 'METHPDPYMU', 'ANOSTMPYMU', 'PROVPDPYMU', 'STMOTHPYMU2', 'ZOLPPDPYMU', 'ESZOPDPYMU', 'SVBENZPYMU', 'SEDOTHPYMU2', 'BENZOSPYMU', 'ALCYDAYS', 'MRJYDAYS', 'COCYDAYS', 'CRKYDAYS', 'HERYDAYS', 'HALLNDAYYR', 'INHNDAYYR', 'METHNDAYYR', 'CIGMDAYS', 'CGRMDAYS', 'SMKLSMDAYS', 'ALCMDAYS', 'MRJMDAYS', 'COCMDAYS', 'CRKMDAYS', 'HERMDAYS', 'HALLNDAYPM', 'INHNDAYPM', 'METHNDAYPM', 'PNRNDAYPM', 'TRQNDAYPM', 'STMNDAYPM', 'SEDNDAYPM', 'BNGDRMDAYS', 'CIGPDAY', 'CIG1PACK', 'CIGAVGD', 'CIGAVGM', 'ALCNUMDKPM', 'FUCIG18', 'FUCIG21', 'FUCD218', 'FUCD221', 'FUCGR18', 'FUCGR21', 'FUSMKLSS18', 'FUSMKLSS21', 'FUALC18', 'FUALC21', 'FUMJ18', 'FUMJ21', 'FUCOC18', 'FUCOC21', 'FUCRK18', 'FUCRK21', 'FUHER18', 'FUHER21', 'FUHALLUC18', 'FUHALLUC21', 'FULSD18', 'FULSD21', 'FUPCP18', 'FUPCP21', 'FUECSTMO18', 'FUECSTMO21', 'FUINHAL18', 'FUINHAL21', 'FUMETHAM18', 'FUMETHAM21', 'FUPNRNM18', 'FUPNRNM21', 'FUTRQNM18', 'FUTRQNM21', 'FUSTMNM18', 'FUSTMNM21', 'FUSEDNM18', 'FUSEDNM21', 'PNRMAINRSN', 'TRQMAINRSN', 'STMMAINRSN', 'SEDMAINRSN', 'SRCPNRNM2', 'SRCTRQNM2', 'SRCSTMNM2', 'SRCSEDNM2', 'SRCFRPNRNM', 'SRCFRTRQNM', 'SRCFRSTMNM', 'SRCFRSEDNM', 'SRCCLFRPNR', 'SRCCLFRTRQ', 'SRCCLFRSTM', 'SRCCLFRSED', 'COLDMEDS', 'COLDREC', 'COLDYR1', 'COLDYR2', 'COLDYR3', 'COLDYR4', 'COLDYR5', 'OTCFLAG', 'GHB', 'GHBREC', 'COCNEEDL', 'CONDLREC', 'HERSMOKE', 'HRSMKREC', 'HERSNIFF', 'HRSNFREC', 'HERNEEDL', 'HEOTSMK', 'HEOTSNF', 'HEOTNDL', 'HEOTOTH', 'HEOTSP', 'HRNDLREC', 'METHNEEDL', 'METHNDLRC', 'OTDGNEDL', 'OTDGNDLA', 'OTDGNDLB', 'OTDGNDLC', 'OTDGNDLD', 'OTDGNDLE', 'OTDGNDLRC', 'GNNDREUS', 'GNNDLSH1', 'GNNDCLEN', 'GNNDLSH2', 'GNNDGET2', 'ANYNDLREC', 'CHMNDLREC', 'ANYNEEDL', 'NEDHER', 'NEDCOC', 'METHNEEDL2', 'HERSMOK2', 'HERSNIF2', 'COLDFLGR', 'COLDYRR', 'COLDMONR', 'GHBFLGR', 'GHBYRR', 'GHBMONR', 'RSKCIGPKD', 'RSKMRJMON', 'RSKMRJWK', 'RSKLSDTRY', 'RSKLSDWK', 'RSKHERTRY', 'RSKHERWK', 'RSKCOCMON', 'RSKCOCWK', 'RSKBNGDLY', 'RSKBNGWK', 'DIFGETMRJ', 'DIFGETLSD', 'DIFGETCOC', 'DIFGETCRK', 'DIFGETHER', 'APPDRGMON', 'RSKYFQDGR', 'RSKYFQTES', 'RKFQPBLT', 'RKFQDBLT', 'GRSKCIGPKD', 'GRSKMRJMON', 'GRSKMRJWK', 'GRSKCOCMON', 'GRSKCOCWK', 'GRSKHERTRY', 'GRSKHERWK', 'GRSKLSDTRY', 'GRSKLSDWK', 'GRSKBNGDLY', 'GRSKBNGWK', 'DIFOBTMRJ', 'DIFOBTCOC', 'DIFOBTCRK', 'DIFOBTHER', 'DIFOBTLSD', 'APPDRGMON2', 'BLNTEVER', 'BLNTAGE', 'BLNTYFU', 'BLNTMFU', 'BLNTREC', 'BLRECFL2', 'BLNT30DY','BLNT30C1', 'BLNT30C2', 'RSNOMRJ', 'RSNMRJMO', 'BLNTNOMJ', 'MEDMJYR', 'MEDMJALL', 'MEDMJPA2', 'CIGIRTBL', 'CIGCRAVE', 'CIGCRAGP', 'CIGINCTL', 'CIGAVOID', 'CIGFNSMK', 'CIGFNLKE', 'CIGPLANE', 'CIGRNOUT', 'CIGREGDY', 'CIGREGWK', 'CIGREGNM', 'CIGNMCHG', 'CIGSVLHR', 'CIGINFLU', 'CIGNOINF', 'CIGINCRS', 'CIGSATIS', 'CIGLOTMR', 'CIGWAKE', 'ALCLOTTM', 'ALCGTOVR', 'ALCLIMIT', 'ALCKPLMT', 'ALCNDMOR', 'ALCLSEFX', 'ALCCUTDN', 'ALCCUTEV', 'ALCCUT1X', 'ALCWD2SX', 'ALCWDSMT', 'ALCEMOPB', 'ALCEMCTD', 'ALCPHLPB', 'ALCPHCTD', 'ALCLSACT', 'ALCSERPB', 'ALCPDANG', 'ALCLAWTR', 'ALCFMFPB', 'ALCFMCTD', 'MRJLOTTM', 'MRJGTOVR', 'MRJLIMIT', 'MRJKPLMT', 'MRJNDMOR', 'MRJLSEFX', 'MRJCUTDN', 'MRJCUTEV', 'MRJEMOPB', 'MRJEMCTD', 'MRJPHLPB', 'MRJPHCTD', 'MRJLSACT', 'MRJSERPB', 'MRJPDANG', 'MRJLAWTR', 'MRJFMFPB', 'MRJFMCTD', 'COCLOTTM', 'COCGTOVR', 'COCLIMIT', 'COCKPLMT', 'COCNDMOR', 'COCLSEFX', 'COCCUTDN', 'COCCUTEV', 'COCCUT1X', 'COCFLBLU', 'COCWD2SX', 'COCWDSMT', 'COCEMOPB', 'COCEMCTD', 'COCPHLPB', 'COCPHCTD', 'COCLSACT', 'COCSERPB', 'COCPDANG', 'COCLAWTR', 'COCFMFPB', 'COCFMCTD', 'HERLOTTM', 'HERGTOVR', 'HERLIMIT', 'HERKPLMT', 'HERNDMOR', 'HERLSEFX', 'HERCUTDN', 'HERCUTEV', 'HERCUT1X', 'HERWD3SX', 'HERWDSMT', 'HEREMOPB', 'HEREMCTD', 'HERPHLPB', 'HERPHCTD', 'HERLSACT', 'HERSERPB', 'HERPDANG', 'HERLAWTR', 'HERFMFPB', 'HERFMCTD', 'HALULOTTM', 'HALUGTOVR', 'HALULIMIT', 'HALUKPLMT', 'HALUNDMOR', 'HALULSEFX', 'HALUCUTDN', 'HALUCUTEV', 'HALUEMOPB', 'HALUEMCTD', 'HALUPHLPB', 'HALUPHCTD', 'HALULSACT', 'HALUSERPB', 'HALUPDANG', 'HALULAWTR', 'HALUFMFPB', 'HALUFMCTD', 'INHLLOTTM', 'INHLGTOVR', 'INHLLIMIT', 'INHLKPLMT', 'INHLNDMOR', 'INHLLSEFX', 'INHLCUTDN', 'INHLCUTEV', 'INHLEMOPB', 'INHLEMCTD', 'INHLPHLPB', 'INHLPHCTD', 'INHLLSACT', 'INHLSERPB', 'INHLPDANG', 'INHLLAWTR', 'INHLFMFPB', 'INHLFMCTD', 'METHLOTTM', 'METHGTOVR']\n",
    "col_names_2 = ['METHLIMIT', 'METHKPLMT', 'METHNDMOR', 'METHLSEFX', 'METHCUTDN', 'METHCUTEV', 'METHCUT1X', 'METHFLBLU', 'METHWD2SX', 'METHWDSMT', 'METHEMOPB', 'METHEMCTD', 'METHPHLPB', 'METHPHCTD', 'METHLSACT', 'METHSERPB', 'METHPDANG', 'METHLAWTR', 'METHFMFPB', 'METHFMCTD', 'PNRLLOTTM', 'PNRLGTOVR', 'PNRLLIMIT', 'PNRLKPLMT', 'PNRLNDMOR', 'PNRLLSEFX', 'PNRLCUTDN', 'PNRLCUTEV', 'PNRLCUT1X', 'PNRLWD3SX', 'PNRLWDSMT', 'PNRLEMOPB', 'PNRLEMCTD', 'PNRLPHLPB', 'PNRLPHCTD', 'PNRLLSACT', 'PNRLSERPB', 'PNRLPDANG', 'PNRLLAWTR', 'PNRLFMFPB', 'PNRLFMCTD', 'TRQLLOTTM', 'TRQLGTOVR', 'TRQLLIMIT', 'TRQLKPLMT', 'TRQLNDMOR', 'TRQLLSEFT', 'TRQLCUTDN', 'TRQLCUTEV', 'TRQLEMOPB', 'TRQLEMCTD', 'TRQLPHLPB', 'TRQLPHCTD', 'TRQLLSACT', 'TRQLSERPB', 'TRQLPDANG', 'TRQLLAWTR', 'TRQLFMFPB', 'TRQLFMCTD', 'STIMLOTTM', 'STIMGTOVR', 'STIMLIMIT', 'STIMKPLMT', 'STIMNDMOR', 'STIMLSEFX', 'STIMCUTDN', 'STIMCUTEV', 'STIMCUT1X', 'STIMFLBLU', 'STIMWD2SX', 'STIMWDSMT', 'STIMEMOPB', 'STIMEMCTD', 'STIMPHLPB', 'STIMPHCTD', 'STIMLSACT', 'STIMSERPB', 'STIMPDANG', 'STIMLAWTR', 'STIMFMFPB', 'STIMFMCTD', 'SEDVLOTTM', 'SEDVGTOVR', 'SEDVLIMIT', 'SEDVKPLMT', 'SEDVNDMOR', 'SEDVLSEFX', 'SEDVCUTDN', 'SEDVCUTEV', 'SEDVCUT1X', 'SEDVWD1SX', 'SEDVWDSMT', 'SEDVEMOPB', 'SEDVEMCTD', 'SEDVPHLPB', 'SEDVPHCTD', 'SEDVLSACT', 'SEDVSERPB', 'SEDVPDANG', 'SEDVLAWTR', 'SEDVFMFPB', 'SEDVFMCTD', 'DEPENDHAL', 'DEPENDINH', 'DEPENDMTH', 'DEPENDPNR', 'DEPENDTRQ', 'DEPENDSTM', 'DEPENDSED', 'ABUPOSHAL', 'ABUPOSINH', 'ABUPOSMTH', 'ABUPOSPNR', 'ABUPOSTRQ', 'ABUPOSSTM', 'ABUPOSSED', 'IRCGIRTB', 'IICGIRTB', 'IRCGCRV', 'IICGCRV', 'IRCGCRGP', 'IICGCRGP', 'IRCGNCTL', 'IICGNCTL', 'IRCGAVD', 'IICGAVD', 'IRCGPLN', 'IICGPLN', 'IRCGROUT', 'IICGROUT', 'IRCGRGDY', 'IICGRGDY', 'IRCGRGWK', 'IICGRGWK', 'IRCGRGNM', 'IICGRGNM', 'IRCGNCG', 'IICGNCG', 'IRCGSLHR', 'IICGSLHR', 'IRCGINFL', 'IICGINFL', 'IRCGNINF', 'IICGNINF', 'IRCGINCR', 'IICGINCR', 'IRCGSAT', 'IICGSAT', 'IRCGLMR', 'IICGLMR', 'IRDEPENDHAL', 'IIDEPENDHAL', 'IRDEPENDINH', 'IIDEPENDINH', 'IRDEPENDMTH', 'IIDEPENDMTH', 'IRDEPENDPNR', 'IIDEPENDPNR', 'IRDEPENDTRQ', 'IIDEPENDTRQ', 'IRDEPENDSTM', 'IIDEPENDSTM', 'IRDEPENDSED', 'IIDEPENDSED', 'IRABUPOSHAL', 'IIABUPOSHAL', 'IRABUPOSINH', 'IIABUPOSINH', 'IRABUPOSMTH', 'IIABUPOSMTH', 'IRABUPOSPNR', 'IIABUPOSPNR', 'IRABUPOSTRQ', 'IIABUPOSTRQ', 'IRABUPOSSTM', 'IIABUPOSSTM', 'IRABUPOSSED', 'IIABUPOSSED', 'NDSSANSP', 'NDSSDNSP', 'FTNDDNSP', 'DNICNSP', 'DEPNDALC', 'DEPNDMRJ', 'DEPNDCOC', 'DEPNDHER', 'DEPNDPYHAL', 'DEPNDPYINH', 'DEPNDPYMTH', 'DEPNDPYPNR', 'DEPNDPYTRQ', 'DEPNDPYSTM', 'DEPNDPYSED', 'DEPNDPYPSY', 'DEPNDPYILL', 'DEPNDPYIEM', 'DPPYILLALC', 'ABUSEALC', 'ABUSEMRJ', 'ABUSECOC', 'ABUSEHER', 'ABUSEPYHAL', 'ABUSEPYINH', 'ABUSEPYMTH', 'ABUSEPYPNR', 'ABUSEPYTRQ', 'ABUSEPYSTM', 'ABUSEPYSED', 'ABUSEPYPSY', 'ABUSEPYILL', 'ABUSEPYIEM', 'ABPYILLALC', 'ABODALC', 'ABODMRJ', 'ABODCOC', 'ABODHER', 'UDPYHAL', 'UDPYINH', 'UDPYMTH', 'UDPYPNR', 'UDPYTRQ', 'UDPYSTM', 'UDPYSED', 'UDPYTRQSED', 'UDPYPSY', 'UDPYOPI', 'UDPYHRPNR', 'UDPYILL', 'UDPYIEM', 'UDPYILAL', 'UDPYILAAL', 'DUDNOAUD', 'AUDNODUD', 'BOOKED', 'NOBOOKY2', 'BKMVTHFT', 'BKLARCNY', 'BKBURGL', 'BKSRVIOL', 'BKSMASLT', 'BKROB', 'BKARSON', 'BKDRVINF', 'BKDRUNK', 'BKPOSTOB', 'BKDRUG', 'BKSEXNR', 'BKFRAUD', 'BKOTH', 'BKOTHOF2', 'PROBATON', 'PAROLREL', 'DRVINALCO', 'DRVINMARJ', 'DRVINCOCN', 'DRVINHERN', 'DRVINHALL', 'DRVININHL', 'DRVINMETH', 'DRVINALON', 'MXMJPNLT', 'DRVINALCO2', 'DRVINMARJ2', 'DRVINDRG', 'DRVINDROTMJ', 'DRVINALDRG', 'PAROL', 'PROB', 'MRJYRBFR', 'MRJAGLST', 'MRJYLU', 'MRJMLU', 'CIGAGLST', 'CIGYLU', 'CIGMLU', 'CIGDLLST', 'CIGDLYLU', 'CIGDLMLU', 'SMKAGLAST', 'SMKYRLAST', 'SMKMOLAST', 'CGRAGLST', 'CIGARYLU', 'CIGARMLU', 'ALCAGLST', 'ALCYLU', 'ALCMLU', 'COCAGLST', 'COCYLU', 'COCMLU', 'CRKAGLST', 'CRKYLU', 'CRKMLU', 'HERAGLST', 'HERYLU', 'HERMLU', 'HALLAGLST', 'HALLYRLST', 'HALLMOLST', 'LSDAGLST', 'LSDYLU', 'LSDMLU', 'PCPAGLST', 'PCPYLU', 'PCPMLU', 'ECSTMOAGL', 'ECSTMOYLU', 'ECSTMOMLU', 'INHLAGLST', 'INHLYRLST', 'INHLMOLST', 'METHAGLST', 'METHYRLST', 'METHMOLST', 'CIGYRBFR', 'ALCYRBFR', 'COCYRBFR', 'TXEVRRCVD', 'TXYRRECVD', 'TXYRALDGB', 'TXYRHOSOV', 'TXYRHOSAD', 'TXYRRESOV', 'TXYRRESAD', 'TXYROUTPT', 'TXYROUTAD', 'TXYRMHCOP', 'TXYRMHCAD', 'TXYREMRGN', 'TXYREMRAD', 'TXYRDRPRV', 'TXYRDRPAD', 'TXYRPRISN', 'TXYRPRIAD', 'TXYRSLFHP', 'TXYRSLFAD', 'TXYROTHER', 'TXYROTHSP2', 'TXYROTHAD', 'TXYRERDRG', 'TXYRERNUM2', 'TXCURRENT', 'NDTXYRADG', 'NDMORTXYR', 'NDMORTALC', 'NDMORTMRJ', 'NDMORTCOC', 'NDMORTHER', 'NDMORTHAL', 'NDMORTINH', 'NDMORTMTH', 'NDMORTPNR', 'NDMORTTRQ', 'NDMORTSTM', 'NDMORTSED', 'NDMORTOTH', 'NDTXYRALC', 'NDTXYRMRJ', 'NDTXYRCOC', 'NDTXYRHER', 'NDTXYRHAL', 'NDTXYRINH', 'NDTXYRMTH', 'NDTXYRPNR', 'NDTXYRTRQ', 'NDTXYRSTM', 'NDTXYRSED', 'NDTXYROTH', 'NDTXYOTH1', 'NDTXYOTH2', 'NDTXYOTH3', 'NDTXYOTH4', 'NDTXYOTH5', 'NDTXEFFRT', 'NDTXNOCOV', 'NDTXNOTPY', 'NDTXTSPHR', 'NDTXWANTD', 'NDTXNSTOP', 'NDTXPFULL', 'NDTXDKWHR', 'NDTXNBRNG', 'NDTXJOBNG', 'NDTXNONED', 'NDTXHANDL', 'NDTXNOHLP', 'NDTXNTIME', 'NDTXFNDOU', 'NDTXOTRSN', 'NDTXMIMPT', 'NDMREFFRT', 'NDMRNOCOV', 'NDMRNOTPY', 'NDMRTSPHR', 'NDMRWANTD', 'NDMRNSTOP', 'NDMRPFULL', 'NDMRDKWHR', 'NDMRNBRNG', 'NDMRJOBNG', 'NDMRNONED', 'NDMRHANDL', 'NDMRNOHLP', 'NDMRNTIME', 'NDMRFNDOU', 'NDMROTRSN', 'NDMRMIMPT', 'TXRCVDREC', 'TXLTYMNPL2', 'TXLTYALCO', 'TXLTYMRJH', 'TXLTYCOCN', 'TXLTYHERN', 'TXLTYHALL', 'TXLTYINHL', 'TXLTYMETH', 'TXLTYPNRL', 'TXLTYTRQL', 'TXLTYSTIM', 'TXLTYSEDV', 'TXLTYOTHR', 'TXLTYMAIN2', 'TXLTYOCOM2', 'TXLTYDAYS2', 'TXPAYHINS', 'TXPAYMCRE', 'TXPAYMCAD', 'TXPAYPUBL', 'TXPAYSVNG', 'TXPAYFAML', 'TXPAYCOUR', 'TXPAYMILT', 'TXPAYBOSS', 'TXPAYOTHR', 'TXPAYOTSP2', 'TXPAYFREE', 'TXENRLOCT', 'TXYRONDTX', 'TXALCONLY', 'TXALCONAG', 'TXDRGONLY', 'TXDRGONAG', 'TXALCDRGU', 'TXALCDAGE', 'TXDRGALCU', 'TXDRGAAGE', 'TXYALONAG', 'TXYALODRG', 'TXYALODAG', 'TXYDRONAG', 'TXYDROALC', 'TXYDROAAG', 'TXYALDAAG', 'TXYALDDAG', 'TXFGALAGE', 'TXFGDGAGE', 'TXFGADAGE', 'TXSHGWENT', 'TXSHGALDB', 'TXSHGFLAG', 'TXEVRRCVD2', 'TXYRALC', 'TXYRILL', 'TXYRALNIL', 'TXYRILNAL', 'TXYRRECVD2', 'TXYRILANAL', 'TXLTYALCO2', 'TXLTYMRJH2', 'TXLTYCOCN2', 'TXLTYHERN2', 'TXLTYHALL2', 'TXLTYINHL2', 'TXLTYMETH2', 'TXLTYPNRL2', 'TXLTYTRQL2', 'TXLTYSTIM2', 'TXLTYSEDV2', 'TXLTYILL', 'TXPAYHINS2', 'TXPAYMCRE2', 'TXPAYMCAD2', 'TXPAYPUBL2', 'TXPAYSVNG2', 'TXPAYFAML2', 'TXPAYCOUR2', 'TXPAYMILT2', 'TXPAYBOSS2', 'TXPDHINSAL', 'TXPDMCREAL', 'TXPDMCADAL', 'TXPDPUBLAL', 'TXPDSVNGAL', 'TXPDFAMLAL', 'TXPDCOURAL', 'TXPDMILTAL', 'TXPDBOSSAL', 'TXPDHINSIL', 'TXPDMCREIL', 'TXPDMCADIL', 'TXPDPUBLIL', 'TXPDSVNGIL', 'TXPDFAMLIL', 'TXPDCOURIL', 'TXPDMILTIL', 'TXPDBOSSIL', 'TXYRSPALC', 'TXYRSPILL', 'TXYSPALNIL', 'TXYSPILNAL', 'TXYRSPILAL', 'TXYSILANAL', 'TXLTCURRSP', 'TXYRHOSAL', 'TXYRRESAL', 'TXYROUTAL', 'TXYRMHCAL', 'TXYREMRAL', 'TXYRDRPAL', 'TXYRPRIAL', 'TXYRSLFAL', 'TXYRHOSIL', 'TXYRRESIL', 'TXYROUTIL', 'TXYRMHCIL', 'TXYREMRIL', 'TXYRDRPIL', 'TXYRPRIIL', 'TXYRSLFIL', 'TXYRHOSOV2', 'TXYRRESOV2', 'TXYROUTPT2', 'TXYRMHCOP2', 'TXYREMRGN2', 'TXYRDRPRV2', 'TXYRPRISN2', 'TXYRSLFHP2', 'TXYRNDALC', 'TXYRNDILL', 'TXYRNDILAL', 'NDFLTXALC', 'NDFLTXILL', 'NDFLTXILAL', 'NDTXEFTALC', 'NDTXEFTILL', 'NDTXEFILAL', 'TXYRNOSPAL', 'TXYRNOSPIL', 'TXYNSPILAL', 'NDTRNNOCOV', 'NDTRNNOTPY', 'NDTRNTSPHR', 'NDTRNWANTD', 'NDTRNNSTOP', 'NDTRNPFULL', 'NDTRNDKWHR', 'NDTRNNBRNG', 'NDTRNJOBNG', 'NDTRNNONED', 'NDTRNHANDL', 'NDTRNNOHLP', 'NDTRNNTIME', 'NDTRNFNDOU', 'NDTRNMIMPT', 'PREGNANT', 'HTANSWER', 'HTINCHE2', 'WTANSWER', 'WTPOUND2', 'NMERTMT2', 'INHOSPYR', 'NMNGTHS2', 'NMVSOPT2', 'NMVSOEST', 'HPUSETOB', 'HPUSEALC', 'HPUSEDRG', 'HPQTTOB', 'HPALCAMT', 'HPALCFRQ', 'HPALCPRB', 'HPALCCUT', 'HPALCTX', 'HPALCNOT', 'HPDRGTALK', 'STDANYYR', 'HRTCONDEV', 'DIABETEVR', 'COPDEVER', 'CIRROSEVR', 'HEPBCEVER', 'KIDNYDSEV', 'ASTHMAEVR', 'HIVAIDSEV', 'CANCEREVR', 'HIGHBPEVR', 'NONABOVEV', 'CABLADDER', 'CABLOLEULYM', 'CAOTHER2', 'CABREAST', 'CACERVIX', 'CACOLNRECT', 'CAESOPSTOM', 'CAGALLIVPAN', 'CAKIDNEY', 'CALARYLUNG', 'CAMELANOM', 'CAMOUTTHRO', 'CAOVARY', 'CAPROSTEST', 'CASKINOTH', 'CASKINDK', 'CATHYROID', 'CAUTERUS', 'CANCERYR', 'HRTCONDAG', 'HRTCONDYR', 'DIABETEAG', 'COPDAGE', 'CIRROSAGE', 'HEPBCAGE', 'KIDNYDSAG', 'ASTHMAAGE', 'ASTHMANOW', 'HIVAIDSAG', 'HIGHBPMED', 'HIGHBPAGE', 'PREG', 'PREG2', 'TRIMEST', 'BMI2']\n",
    "col_names_3 = ['AUINPYR', 'AUINPSYH', 'AUINPGEN', 'AUINMEDU', 'AUINAHSP', 'AUINRESD', 'AUINSFAC', 'AUNMPSY2', 'AUNMPGE2', 'AUNMMED2', 'AUNMAHS2', 'AUNMRES2', 'AUNMSFA2', 'AUPINSLF', 'AUPINOFM', 'AUPINPHI', 'AUPINMCR', 'AUPINMCD', 'AUPINREH', 'AUPINEMP', 'AUPINMIL', 'AUPINPUB', 'AUPINPRV', 'AUPINFRE', 'AUPINFM2', 'AUOPTYR', 'AUOPMENT', 'AUOPTHER', 'AUOPDOC', 'AUOPCLNC', 'AUOPDTMT', 'AUOPOTOP', 'AUOPYRS2', 'AUNMMEN2', 'AUNMTHE2', 'AUNMDOC2', 'AUNMCLN2', 'AUNMDTM2', 'AUNMOTO2', 'AUPOPSLF', 'AUPOPOFM', 'AUPOPPHI', 'AUPOPMCR', 'AUPOPMCD', 'AUPOPREH', 'AUPOPEMP', 'AUPOPMIL', 'AUPOPPUB', 'AUPOPPRV', 'AUPOPFRE', 'AUPOPMOS', 'AUPOPAMT', 'AURXYR', 'AUUNMTYR', 'AUUNCOST', 'AUUNNBR', 'AUUNJOB', 'AUUNNCOV', 'AUUNENUF', 'AUUNWHER', 'AUUNCFID', 'AUUNCMIT', 'AUUNNOND', 'AUUNHNDL', 'AUUNNHLP', 'AUUNBUSY', 'AUUNFOUT', 'AUUNNTSP', 'AUUNSOR', 'AUUNRIM2', 'AUALTYR', 'AUALACUP', 'AUALCHIR', 'AUALHERB', 'AUALSGRP', 'AUALINET', 'AUALRELG', 'AUALHLIN', 'AUALMASG', 'AUALOTH', 'AUALOTS2', 'AUMOTVYR', 'AMHINP2', 'AMHOUTP3', 'AMHRX2', 'AMHTXRC3', 'AMHSVTYP', 'AMHTXND2', 'AMHTXAND', 'MHLMNT3', 'MHLTHER3', 'MHLDOC3', 'MHLCLNC3', 'MHLDTMT3', 'MHLSCHL3', 'MHLOTH3', 'MHPDSLF2', 'MHPDOFM2', 'MHPDPHI2', 'MHPDMCR2', 'MHPDMCD2', 'MHPDREH2', 'MHPDEMP2', 'MHPDMIL2', 'MHPDPUB2', 'MHPDPRV2', 'MHPDFRE2', 'MHRCOST2', 'MHRNBRS2', 'MHRJOBS2', 'MHRNCOV2', 'MHRENUF2', 'MHRWHER2', 'MHRCFID2', 'MHRCMIT2', 'MHRNOND2', 'MHRHAND2', 'MHRNOHP2', 'MHRTIME2', 'MHRFOUT2', 'MHRTRAN2', 'MHRSOTH2', 'RCVMHOSPTX', 'RCVMHNSPTX', 'RCVSPTXNMH', 'RCVMHASPTX', 'SNYSELL', 'SNYSTOLE', 'SNYATTAK', 'SNFAMJEV', 'SNRLGSVC', 'SNRLGIMP', 'SNRLDCSN', 'SNRLFRND', 'YEATNDYR', 'YEHMSLYR', 'YESCHFLT', 'YESCHWRK', 'YESCHIMP', 'YESCHINT', 'YETCGJOB', 'YELSTGRD', 'YESTSCIG', 'YESTSMJ', 'YESTSALC', 'YESTSDNK', 'YEPCHKHW', 'YEPHLPHW', 'YEPCHORE', 'YEPLMTTV', 'YEPLMTSN', 'YEPGDJOB', 'YEPPROUD', 'YEYARGUP', 'YEYFGTSW', 'YEYFGTGP', 'YEYHGUN', 'YEYSELL', 'YEYSTOLE', 'YEYATTAK', 'YEPPKCIG', 'YEPMJEVR', 'YEPMJMO', 'YEPALDLY', 'YEGPKCIG', 'YEGMJEVR', 'YEGMJMO', 'YEGALDLY', 'YEFPKCIG', 'YEFMJEVR', 'YEFMJMO', 'YEFALDLY', 'YETLKNON', 'YETLKPAR', 'YETLKBGF', 'YETLKOTA', 'YETLKSOP', 'YEPRTDNG', 'YEPRBSLV', 'YEVIOPRV', 'YEDGPRGP', 'YESLFHLP', 'YEPRGSTD', 'YESCHACT', 'YECOMACT', 'YEFAIACT', 'YEOTHACT', 'YEDECLAS', 'YEDERGLR', 'YEDESPCL', 'YEPVNTYR', 'YERLGSVC', 'YERLGIMP', 'YERLDCSN', 'YERLFRND', 'SCHFELT', 'TCHGJOB', 'AVGGRADE', 'STNDSCIG', 'STNDSMJ', 'STNDALC', 'STNDDNK', 'PARCHKHW', 'PARHLPHW', 'PRCHORE2', 'PRLMTTV2', 'PARLMTSN', 'PRGDJOB2', 'PRPROUD2', 'ARGUPAR', 'YOFIGHT2', 'YOGRPFT2', 'YOHGUN2', 'YOSELL2', 'YOSTOLE2', 'YOATTAK2', 'PRPKCIG2', 'PRMJEVR2', 'PRMJMO', 'PRALDLY2', 'YFLPKCG2', 'YFLTMRJ2', 'YFLMJMO', 'YFLADLY2', 'FRDPCIG2', 'FRDMEVR2', 'FRDMJMON', 'FRDADLY2', 'TALKPROB', 'PRTALK3', 'PRBSOLV2', 'PREVIOL2', 'PRVDRGO2', 'GRPCNSL2', 'PREGPGM2', 'YTHACT2', 'DRPRVME3', 'ANYEDUC3', 'RLGATTD', 'RLGIMPT', 'RLGDCSN', 'RLGFRND', 'DSTNRV30', 'DSTHOP30', 'DSTRST30', 'DSTCHR30', 'DSTEFF30', 'DSTNGD30', 'DSTWORST', 'DSTNRV12', 'DSTHOP12', 'DSTRST12', 'DSTCHR12', 'DSTEFF12', 'DSTNGD12', 'IMPREMEM', 'IMPCONCN', 'IMPGOUT', 'IMPGOUTM', 'IMPPEOP', 'IMPPEOPM', 'IMPSOC', 'IMPSOCM', 'IMPHHLD', 'IMPHHLDM', 'IMPRESP', 'IMPRESPM', 'IMPWORK', 'IMPWEEKS', 'IMPDYFRQ', 'IMPYDAYS', 'SUICTHNK', 'SUICPLAN', 'SUICTRY', 'K6SCMON', 'SPDMON', 'K6SCYR', 'K6SCMAX', 'SPDYR', 'MHSUITHK', 'MHSUTK_U', 'MHSUIPLN', 'MHSUITRY', 'WSPDSC2', 'WHODASC2', 'WHODASC3', 'SMIPP_U', 'SMIYR_U', 'AMIYR_U', 'SMMIYR_U', 'MMIYR_U', 'LMIYR_U', 'LMMIYRU', 'MI_CAT_U', 'SMISUDPY', 'AMISUDPY', 'LMMISUDPY', 'ADDPREV', 'ADDSCEV', 'ADLOSEV', 'ADDPDISC', 'ADDPLSIN', 'ADDSLSIN', 'ADLSI2WK', 'ADDPR2WK', 'ADWRHRS', 'ADWRDST', 'ADWRCHR', 'ADWRIMP', 'ADDPPROB', 'ADWRPROB', 'ADWRAGE', 'ADWRDEPR', 'ADWRDISC', 'ADWRLSIN', 'ADWRPLSR', 'ADWRELES', 'ADWREMOR', 'ADWRGAIN', 'ADWRGROW', 'ADWRPREG', 'ADWRGNL2', 'ADWRLOSE', 'ADWRDIET', 'ADWRLSL2', 'ADWRSLEP', 'ADWRSMOR', 'ADWRENRG', 'ADWRSLOW', 'ADWRSLNO', 'ADWRJITT', 'ADWRJINO', 'ADWRTHOT', 'ADWRCONC', 'ADWRDCSN', 'ADWRNOGD', 'ADWRWRTH', 'ADWRDLOT', 'ADWRDBTR', 'ADWRSTHK', 'ADWRSPLN', 'ADWRSATP', 'AD_MDEA1', 'AD_MDEA2', 'AD_MDEA3', 'AD_MDEA4', 'AD_MDEA5', 'AD_MDEA6', 'AD_MDEA7', 'AD_MDEA8', 'AD_MDEA9', 'ADSMMDEA', 'ADPBINTF', 'ADPBDLYA', 'ADPBRMBR', 'ADPBAGE', 'ADPBNUM', 'ADPB2WK', 'ADPSHMGT', 'ADPSWORK', 'ADPSRELS', 'ADPSSOC', 'ADPSDAYS', 'ADSEEDOC', 'ADFAMDOC', 'ADOTHDOC', 'ADPSYCH', 'ADPSYMD', 'ADSOCWRK', 'ADCOUNS', 'ADOTHMHP', 'ADNURSE', 'ADRELIG', 'ADHERBAL', 'ADOTHHLP', 'ADTMTNOW', 'ADRX12MO', 'ADRXNOW', 'ADRXHLP', 'ADTMTHLP', 'AMDELT', 'AMDEYR', 'AMDEY2_U', 'ATXMDEYR', 'ARXMDEYR', 'AMDETXRX', 'ADOCMDE', 'AOMDMDE', 'APSY1MDE', 'APSY2MDE', 'ASOCMDE', 'ACOUNMDE', 'AOMHMDE', 'ANURSMDE', 'ARELMDE', 'AHBCHMDE', 'AOTHMDE', 'AHLTMDE', 'AALTMDE', 'ASDSHOM2', 'ASDSWRK2', 'ASDSREL2', 'ASDSSOC2', 'ASDSOVL2', 'AMDEIMP', 'YUHOSPYR', 'YUHOSPN2', 'YUHOSUIC', 'YUHODEPR', 'YUHOFEAR', 'YUHOBKRU', 'YUHOEATP', 'YUHOANGR', 'YUHOFITE', 'YUHOFMLY', 'YUHOFRND', 'YUHOOTPP', 'YUHOSCHL', 'YUHOSOR', 'YURSIDYR', 'YURSIDN2', 'YURSSUIC', 'YURSDEPR', 'YURSFEAR', 'YURSBKRU', 'YURSEATP', 'YURSANGR', 'YURSFITE', 'YURSFMLY', 'YURSFRND', 'YURSOTPP', 'YURSSCHL', 'YURSSOR', 'YUFCARYR', 'YUFCARN2', 'YUFCSUIC', 'YUFCDEPR', 'YUFCFEAR', 'YUFCBKRU', 'YUFCEATP', 'YUFCANGR', 'YUFCFITE', 'YUFCFMLY', 'YUFCFRND', 'YUFCOTPP', 'YUFCSCHL', 'YUFCSOR', 'YUDYTXYR', 'YUDYTXN2', 'YUDYSUIC', 'YUDYDEPR', 'YUDYFEAR', 'YUDYBKRU', 'YUDYEATP', 'YUDYANGR', 'YUDYFITE', 'YUDYFMLY', 'YUDYFRND', 'YUDYOTPP', 'YUDYSCHL', 'YUDYSOR', 'YUMHCRYR', 'YUMHCRN2', 'YUMHSUIC', 'YUMHDEPR', 'YUMHFEAR', 'YUMHBKRU', 'YUMHEATP', 'YUMHANGR', 'YUMHFITE', 'YUMHFMLY', 'YUMHFRND', 'YUMHOTPP', 'YUMHSCHL', 'YUMHSOR', 'YUTPSTYR', 'YUTPSTN2', 'YUTPSUIC', 'YUTPDEPR', 'YUTPFEAR', 'YUTPBKRU', 'YUTPEATP', 'YUTPANGR', 'YUTPFITE', 'YUTPFMLY', 'YUTPFRND', 'YUTPOTPP', 'YUTPSCHL', 'YUTPSOR', 'YUIHTPYR', 'YUIHTPN2', 'YUIHSUIC', 'YUIHDEPR', 'YUIHFEAR', 'YUIHBKRU', 'YUIHEATP', 'YUIHANGR', 'YUIHFITE', 'YUIHFMLY', 'YUIHFRND', 'YUIHOTPP', 'YUIHSCHL', 'YUIHSOR', 'YUFDOCYR', 'YUFDOCN2', 'YUFDSUIC', 'YUFDDEPR', 'YUFDFEAR', 'YUFDBKRU', 'YUFDEATP', 'YUFDANGR', 'YUFDFITE', 'YUFDFMLY', 'YUFDFRND', 'YUFDOTPP', 'YUFDSCHL', 'YUFDSOR', 'YUSWSCYR', 'YUSWSUIC', 'YUSWDEPR', 'YUSWFEAR', 'YUSWBKRU', 'YUSWEATP', 'YUSWANGR', 'YUSWFITE', 'YUSWFMLY', 'YUSWFRND', 'YUSWOTPP', 'YUSWSCHL', 'YUSWSOR', 'YUSCEMYR', 'YUSCPGYR', 'YUJVDTON', 'YUJVDTN2', 'YUJVDTYR', 'YHOSP', 'YRESID', 'YFOST', 'YDAYTRT', 'YCLIN', 'YTHER', 'YHOME', 'YPED', 'YSPEC', 'YSHSW', 'YJAIL', 'ANYMHIN2', 'ANYMHOUT', 'ANYSMH2', 'ANYNSMH', 'ANYMHED2', 'ANYSEDMF', 'HOSPVST', 'RESIDVST', 'FOSTVST', 'DYTXVST', 'CLINVST', 'THERVST', 'HOMEVST', 'SPINVST2', 'SPOUTVST', 'SMHVST2', 'SIMHSUI2', 'SIMHDPR2', 'SIMHFEA2', 'SIMHBRK2', 'SIMHEAT2', 'SIMHANG2', 'SIMHFIT2', 'SIMHFML2', 'SIMHFRD2', 'SIMHOTP2', 'SIMHSCH2', 'SIMHMEN2', 'SIMHOTH3', 'SOMHSUI', 'SOMHDPR', 'SOMHFEA', 'SOMHBRK', 'SOMHEAT', 'SOMHANGR', 'SOMHFITE', 'SOMHFMLY', 'SOMHFRND', 'SOMHOTPP', 'SOMHSCHL', 'SOMHMEND', 'SOMHOTH2', 'SMHSUI2', 'SMHDPR2', 'SMHFEA2', 'SMHBRK2', 'SMHEAT2', 'SMHANGR2', 'SMHFITE2', 'SMHFMLY2', 'SMHFRND2', 'SMHOTPP2', 'SMHSCHL2', 'SMHMEND2', 'SMHOTH3', 'SHSWSUI', 'SHSWDPR', 'SHSWFEA', 'SHSWBRK', 'SHSWEAT', 'SHSWANGR', 'SHSWFITE', 'SHSWFMLY', 'SHSWFRND', 'SHSWOTPP', 'SHSWSCHL', 'SHSWMEND', 'SHSWOTH2', 'FDOCSUI', 'FDOCDPR', 'FDOCFEA', 'FDOCBRK', 'FDOCEAT', 'FDOCANGR', 'FDOCFITE', 'FDOCFMLY', 'FDOCFRND', 'FDOCOTPP', 'FDOCSCHL', 'FDOCMEND', 'FDOCOTH2', 'YMHOSPTX', 'YMHNSPTX', 'YSPTXNMH', 'YMHASPTX', 'YODPREV', 'YODSCEV', 'YOLOSEV', 'YODPDISC', 'YODPLSIN', 'YODSLSIN', 'YOLSI2WK', 'YODPR2WK', 'YOWRHRS', 'YOWRDST', 'YOWRCHR', 'YOWRIMP', 'YODPPROB', 'YOWRPROB', 'YOWRAGE', 'YOWRDEPR', 'YOWRDISC', 'YOWRLSIN', 'YOWRPLSR', 'YOWRELES', 'YOWREMOR', 'YOWRGAIN', 'YOWRGROW', 'YOWRPREG', 'YOWRGNL2', 'YOWRLOSE', 'YOWRDIET', 'YOWRLSL2', 'YOWRSLEP', 'YOWRSMOR', 'YOWRENRG', 'YOWRSLOW', 'YOWRSLNO', 'YOWRJITT', 'YOWRJINO', 'YOWRTHOT', 'YOWRCONC', 'YOWRDCSN', 'YOWRNOGD', 'YOWRWRTH', 'YOWRDLOT', 'YOWRDBTR', 'YOWRSTHK', 'YOWRSPLN', 'YOWRSATP', 'YO_MDEA1', 'YO_MDEA2', 'YO_MDEA3', 'YO_MDEA4', 'YO_MDEA5', 'YO_MDEA6', 'YO_MDEA7', 'YO_MDEA8', 'YO_MDEA9', 'YODSMMDE', 'YOPBINTF', 'YOPBDLYA', 'YOPBRMBR', 'YOPBAGE', 'YOPBNUM', 'YOPB2WK']\n",
    "col_names_4 = ['YOPSHMGT', 'YOPSWORK', 'YOPSRELS', 'YOPSSOC', 'YOPSDAYS', 'YOSEEDOC', 'YOFAMDOC', 'YOOTHDOC', 'YOPSYCH', 'YOPSYMD', 'YOSOCWRK', 'YOCOUNS', 'YOOTHMHP', 'YONURSE', 'YORELIG', 'YOHERBAL', 'YOOTHHLP', 'YOTMTNOW', 'YORX12MO', 'YORXNOW', 'YORXHLP', 'YOTMTHLP', 'YMDELT', 'YMDEYR', 'YMDEAUDPY', 'YMDEIUDPY', 'YMDEUDPY', 'YTXMDEYR', 'YRXMDEYR', 'YMDETXRX', 'YDOCMDE', 'YOMDMDE', 'YPSY1MDE', 'YPSY2MDE', 'YSOCMDE', 'YCOUNMDE', 'YOMHMDE', 'YNURSMDE', 'YRELMDE', 'YHBCHMDE', 'YOTHMDE', 'YHLTMDE', 'YALTMDE', 'YMDEHPRX', 'YMDEHPO', 'YMDERXO2', 'YMDEHARX', 'YSDSHOME', 'YSDSWRK', 'YSDSREL', 'YSDSSOC', 'YSDSOVRL', 'MDEIMPY', 'YMDEIMAUD', 'YMDEIMIUD', 'YMDEIMUDPY', 'CADRLAST', 'CADRPEOP', 'CADRCAR', 'CADRHOME', 'CADROTHM', 'CADRPUBL', 'CADRBAR', 'CADREVNT', 'CADRSCHL', 'CADROTH', 'CADROTS2', 'CABUYFRE', 'CAGVMONY', 'CABUYWHO', 'CABPLACE', 'CABUNDAG', 'CAGVWHO', 'CAFREWHO', 'CAFRESP2', 'CADRKDRUG', 'CADRKMARJ', 'CADRKCOCN', 'CADRKHERN', 'CADRKHALL', 'CADRKINHL', 'CADRKMETH', 'CABINGFLG', 'CABINGEVR', 'CABINGAGE', 'CABINGYFU', 'CABINGMFU', 'EIBINGAGE', 'EIBINGYFU', 'EIBINGMFU', 'CASUPROB', 'CASURCVR', 'CAMHPROB', 'CAMHRCVR', 'KRATEVER', 'KRATREC', 'UADPEOP', 'UADCAR', 'UADHOME', 'UADOTHM', 'UADPUBL', 'UADBAR', 'UADEVNT', 'UADSCHL', 'UADROTH', 'UADOTSP', 'UADPAID', 'UADMONY', 'UADBWHO', 'UADPLACE', 'UADBUND', 'UADCAG', 'UADFWHO', 'UADFRD', 'CADRKMARJ2', 'CADRKCOCN2', 'CADRKHERN2', 'CADRKHALL2', 'CADRKINHL2', 'CADRKMETH2', 'CASUPROB2', 'RCVYSUBPRB', 'CAMHPROB2', 'RCVYMHPRB', 'ALMEDYR2', 'OPMEDYR2', 'ALOPMEDYR', 'KRATFLG', 'KRATYR', 'KRATMON', 'MMGETMJ', 'MMBTREC1', 'MMBTPYR', 'MMBTREC2', 'MMBT30DY', 'MMJNTLOO', 'MMJNTNUM', 'MMJNPCTB', 'MMJNPCAT', 'MMLSUNIT', 'MMLSGMS', 'MMLS10GM', 'MMLSOZS', 'MMLSLBS', 'MMLSPCTB', 'MMLSPCAT', 'MMBUYWHO', 'MMBPLACE', 'MMBPLOS2', 'MMBATJOB', 'MMBCLOSE', 'MMBSELL', 'MMBGIVE', 'MMTRADE', 'MMTRD30D', 'MMTRDREC', 'MMT30FRQ', 'MMTJNTLS', 'MMTJNTNM', 'MMTJWRCB', 'MMTJWRTH', 'MMTLUNIT', 'MMTLGMS', 'MMTLOZS', 'MMTLWRCB', 'MMTLWRTH', 'MMTRDWHO', 'MMTPLACE', 'MMTPLOS2', 'MMTCLOSE', 'MMTKEEP', 'MMTSELL', 'MMTGIVE', 'MMGKEEP', 'MMGSELL', 'MMGGIVE', 'MMFREWHO', 'MMFPLACE', 'MMFPLOS2', 'MMFCLOSE', 'MMFKEEP', 'MMFSELL', 'MMFGIVE', 'LANGVER', 'QUARTER', 'GQTYPE2', 'AGE2', 'NOMARR2', 'SERVICE', 'MILSTAT', 'ACTDEVER', 'ACTD2001', 'ACTD9001', 'ACTD7590', 'ACTDVIET', 'ACTDPRIV', 'COMBATPY', 'HEALTH', 'MOVSINPYR2', 'SEXATRACT', 'SEXIDENT', 'SPEAKENGL', 'DIFFHEAR', 'DIFFSEE', 'DIFFTHINK', 'DIFFWALK', 'DIFFDRESS', 'DIFFERAND', 'IRSEX', 'IRMARIT', 'IIMARIT', 'IREDUHIGHST2', 'IIEDUHIGHST2', 'CATAGE', 'CATAG2', 'CATAG3', 'CATAG6', 'CATAG7', 'PREGAGE2', 'DRVINAGE', 'DRVINDETAG', 'SEXAGE', 'NEWRACE2', 'SEXRACE', 'EDUHIGHCAT', 'HEALTH2', 'EDUSCHLGO', 'EDUSCHGRD2', 'EDUFULPAR', 'EDUSCKMON', 'EDUSCKEST', 'EDUSCKCOM', 'EDUSKPMON', 'EDUSKPEST', 'EDUSKPCOM', 'MILTFAMLY', 'MILTSPPAR', 'MILTPARNT', 'MILTCHLDR', 'MILTSIBLN', 'COLLENRLFT', 'COLLENRLST', 'WRKSTATWK2', 'WRKDPSTWK', 'WRKHADJOB', 'WRKDHRSWK2', 'WRK35WKUS', 'WRKRSNNOT', 'WRKRSNJOB', 'WRKEFFORT', 'WRKDPSTYR', 'WRKSELFEM', 'WRKNUMJOB2', 'WRKNJBPYR', 'WRKNJBWKS', 'WRKLASTYR2', 'WRKSICKMO', 'WRKSKIPMO', 'WRKDRGPOL', 'WRKDRGALB', 'WRKDRGEDU', 'WRKDRGHLP', 'WRKTSTALC', 'WRKTSTDRG', 'WRKTSTHIR', 'WRKTSTRDM', 'WRKTST1ST', 'WRKOKPREH', 'WRKOKRAND', 'IRWRKSTAT', 'IIWRKSTAT', 'II2WRKSTAT', 'IRWRKSTAT18', 'IIWRKSTAT18', 'II2WRKST18', 'EDFAM18', 'IMOTHER', 'IFATHER', 'NRCH17_2', 'IRHHSIZ2', 'IIHHSIZ2', 'IRKI17_2', 'IIKI17_2', 'IRHH65_2', 'IIHH65_2', 'PRXRETRY', 'PRXYDATA', 'MEDICARE', 'CAIDCHIP', 'CHAMPUS', 'PRVHLTIN', 'GRPHLTIN', 'HLTINALC', 'HLTINDRG', 'HLTINMNT', 'HLTINNOS', 'HLCNOTYR', 'HLCNOTMO', 'HLCLAST', 'HLLOSRSN', 'HLNVCOST', 'HLNVOFFR', 'HLNVREF', 'HLNVNEED', 'HLNVSOR', 'IRMEDICR', 'IIMEDICR', 'IRMCDCHP', 'IIMCDCHP', 'IRCHMPUS', 'IICHMPUS', 'IRPRVHLT', 'IIPRVHLT', 'IROTHHLT', 'IIOTHHLT', 'HLCALLFG', 'HLCALL99', 'ANYHLTI2', 'IRINSUR4', 'IIINSUR4', 'OTHINS', 'CELLWRKNG', 'CELLNOTCL', 'IRFAMSOC', 'IIFAMSOC', 'IRFAMSSI', 'IIFAMSSI', 'IRFSTAMP', 'IIFSTAMP', 'IRFAMPMT', 'IIFAMPMT', 'IRFAMSVC', 'IIFAMSVC', 'IRWELMOS', 'IIWELMOS', 'IRPINC3', 'IIPINC3', 'IRFAMIN3', 'IIFAMIN3', 'GOVTPROG', 'INCOME', 'POVERTY3', 'TOOLONG', 'TROUBUND', 'PDEN10', 'COUTYP4', 'MAIIN102', 'AIIND102', 'ANALWT_C', 'VESTR', 'VEREP']\n",
    "\n",
    "starting_length = len(col_names_1) + len(col_names_2) + len(col_names_3) + len(col_names_4)\n",
    "\n",
    "c1 = [c for c in col_names_1 if c[:2].lower()!='ii']\n",
    "c2 = [c for c in col_names_2 if c[:2].lower()!='ii']\n",
    "c3 = [c for c in col_names_3 if c[:2].lower()!='ii']\n",
    "c4 = [c for c in col_names_4 if c[:2].lower()!='ii']\n",
    "\n",
    "# _1 because I'm optimistic about finding more patterns like this\n",
    "reduced_length_1 = len(c1) + len(c2) + len(c3) + len(c4)\n",
    "\n",
    "# Now I'm going to print them out and go through them one section at a time. \n",
    "# no point in copying alllllll of that back in at once.\n",
    "\n",
    "print(c1)\n",
    "\n",
    "# me just figuring stuff out\n",
    "# it's not important\n",
    "# but I'm preserving it because I'm proud of it\n",
    "# I'm a genius, I'm a genius, I'm the smartest person in the world\n",
    "# >>> col_names_1[0]\n",
    "# 'IRCGRFM'\n",
    "# >>> col_names_1[0][:1]=='II'\n",
    "# False\n",
    "# >>> col_names_1[0][:1]=='IR'\n",
    "# False\n",
    "# >>> col_names_1[0][:1]\n",
    "# 'I'\n",
    "# >>> col_names_1[0][:2]\n",
    "# 'IR'\n",
    "# >>> col_names_1[0][:2]=='II'\n",
    "# False\n",
    "# >>> col_names_1[0][:2]=='IR'\n",
    "# True\n",
    "# >>> col_names_1[0][:2].lower()\n",
    "# 'ir'\n",
    "# >>> col_names_1[0][:2].lower()=='ir'\n",
    "# True\n",
    "# >>> col_names_1[0][:2].lower()=='ii'\n",
    "# False\n",
    "# >>> col_names_4[-4]\n",
    "# 'AIIND102'\n",
    "# >>> col_names_4[-4][:2].lower()=='ii'\n",
    "# False\n",
    "# >>> c1 = [c for c in col_names_1]\n",
    "# >>> c1 = c1[:5]\n",
    "# >>> c1\n",
    "# ['IRCGRFM', 'IICGRFM', 'II2CGRFM', 'IRSMKLSS30N', 'IISMKLSS30N']\n",
    "# >>> c1 = [c for c in c1 if c[:2].lower()!='ii']\n",
    "# >>> c1\n",
    "# ['IRCGRFM', 'IRSMKLSS30N']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thursday, May 23, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notes:\n",
    "today I went searching for alternative datasets because the one I'd been working on was taking so long and I thought I probably wouldn't end up being happy with it.  I'm sure I could have done something with it, but I was so excited to be back in queerland and I didn't want to give up on that.  so I went looking and was SHOCKED at how little was available (et tu, taskforce!?), but then I found a dataset from Ilan H. Meyer!!!!  It's a lot smaller than the samhsa one, but it's more specific to queer stuff, and it's Dr. Meyer!!!!  and there are citations from Fingerhut and Frost and Herek and Lisa Diamond and the whole gang!!  I've been so happy playing with it all day; I'm almost getting misty eyed!\n",
    "\n",
    "anyway, work notes.\n",
    "\n",
    "I created my first ever \"project\" in R, which seems to just be a folder that's tacked to one of the side panels.  You can click to open files from there; it's cool!\n",
    "\n",
    "it's a study of queer people across several age groups and across several years. so there's time series stuff in there too, but tbh that scares me a bit.  it'd be cool to do later and i definitely don't want to write it off as \"I can't do that,\" but knowing myself and my proclivity towards taking forever on things and that I do NOT have a resub accomodation on this project AND that it is the super important last project, I want to KISS.  so what I decided to do is look only at the first wave (before the attrition effects kicked in, which were sizable).  it's only n=1518, but it's Ilan Meyer!  I bet they're a good 1518.  Hank seemed somewhat worried about the sample size, but not to the point of it being a dealbreaker.  he said to plow on and we still have time to pivot if my stuff doesn't work.\n",
    "\n",
    "so, I dropped all the features that were exclusive to wave 2 and/or 3, leaving me with 505 features.  then I went thru the codebook and found all the scales they used.  I tracked down the columns where they had calculated the scores, and dropped all the component parts.  I then investigated their imputation process a little bit.  I have some concerns about it (seems weird that more than half of the people who didn't answer the question on IPV would be imputed as NO), but it is very sound in theory and, more importantly, I don't have enough data to drop NAs nor do I have any better ideas on how to impute them.  They *did* the imputation I would have done - regress the missing value on related, populated values, then randomly select a value from the nearest 5 extant values based on something that sounds a lot like KNN.  it seems very robust.  after looking into that, I dropped the non-imputed scale score features, and only kept the imputed ones.\n",
    "\n",
    "after that, I had a little under 400 columns left (quite an achievement, down from 1300+, in just a few hours of work!).  having finally figured out how the scales work, and that they did in fact calculate a lot of these things, I went back to the demographics section of the codebook and looked to see if they did similar stuff there.  it seems like they may have, but I'm not sure.  so far it seems more like they just duplicated their w1q00 variables into columns wiht more semantic names, but I'm just getting started.  that's where to pick up tomorrow.\n",
    "\n",
    "**I think the way forward here is to *NOT* edit scripts from previous days; rather, run them again and pick up where they left off in a new one.**\n",
    "\n",
    "files created: \n",
    "- 2024-05-23_exploring_Meyer_2023_dataset.py\n",
    "- 2024-05-23_set_up.py **NEW SET UP SCRIPT FOR NEW DF!!!!**\n",
    "- 2024-05-23_cols_to_check.txt\n",
    "- 2 folders called 2024-05-23_dowload... in the potential_datasets folder, plus all files within, plus corresponding zip folders.\n",
    "- - the one ending in attempt_2 is the one I ended up using.  they're the same, but the data is formatted nicer.\n",
    "\n",
    "GOALS FOR ~TOMORROW~  NEXT TIME\\*:\n",
    "- finish column cleaning\n",
    "- save a cleaned up (reduced) CSV\n",
    "- start setting up github\n",
    "- make an initial commit\n",
    "\n",
    "\\*may need to use Friday night to work on NN stuff so that you can talk to Hank in flex time if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script 1 in full:\n",
    "# 2024-05-23_set_up.py\n",
    "\n",
    "# Capstone Setup\n",
    "\n",
    "# Module Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime, date, time\n",
    "from string import capwords\n",
    "\n",
    "# Working Directory\n",
    "os.getcwd()\n",
    "#os.chdir('C:/Users/emily/Git_Stuff/General_Assembly/04_Projects/project-capstone')\n",
    "os.listdir()\n",
    "\n",
    "# Import Data\n",
    "meyer = pd.read_csv('./potential_datasets/2024_05_23_download_ICPSR_Meyer_2023_generations_data_attempt_2/ICPSR_37166/DS0007/37166-0007-Data.tsv', sep = '\\t', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script 2 in full\n",
    "# 2024-05-23_exploring_Meyer_2023_dataset.py\n",
    "\n",
    "# 5/23/24\n",
    "\n",
    "# check out this dataset from Ilan Meyer, my beloved\n",
    "\n",
    "# Import Data\n",
    "meyer = pd.read_csv('./potential_datasets/2024_05_23_download_ICPSR_Meyer_2023_generations_data_attempt_2/ICPSR_37166/DS0007/37166-0007-Data.tsv', sep = '\\t', low_memory=False)\n",
    "meyer.shape #(1518, 1329), but we can cut that down.\n",
    "og_columns = list(meyer.columns)\n",
    "\n",
    "# for RIGHT NOW, I think I'm only going to look at wave 1\n",
    "# the wave stuff is REALLY COOL, but i don't think I understand\n",
    "# time series well enough to get into it for this project\n",
    "# if I get a model working based on wave 1, and write it up\n",
    "# and all that \"good enough,\" then I'll come back and add \n",
    "# some time series stuff\n",
    "# oh it can even just be another phase of the project!\n",
    "# no need to replace anything!  just section B.\n",
    "\n",
    "meyer['WAVEPARTICIPATED'].value_counts(dropna =False)\n",
    "# matches what's in the documentation\n",
    "\n",
    "# ok, so, for now, I am going to drop all the variables marked W2 and W3.  \n",
    "cols = list(meyer.columns)\n",
    "w1_cols = [c for c in cols if c[:2]!='W2']\n",
    "w1_cols = [c for c in w1_cols if c[:2]!='W3']\n",
    "len(w1_cols)\n",
    "\n",
    "# drop columns\n",
    "meyer = meyer[w1_cols]\n",
    "meyer.shape\n",
    "\n",
    "# NAs?\n",
    "meyer.isna().sum().sum()\n",
    "# it says 0, but it's not 0\n",
    "# they must have imputed it with an empty string or something\n",
    "# when I do .value_counts(), a lot of columns have a blank row, e.g.,\n",
    "#                      14\n",
    "# where there absolutely should not be a blank.\n",
    "# so that's fun!  gonna have to clean that up!\n",
    "\n",
    "# i originally thought they only included the base variables\n",
    "# and I would have to compute the scale scores myself, but\n",
    "# OMG THEY DID INCLUDE THE CALC'D SCALES!!!!!!\n",
    "# I JUST COULDN'T FIND THEM BECAUSE ALL CAPS!!\n",
    "\n",
    "meyer.columns = [c.lower() for c in list(meyer.columns)]\n",
    "\n",
    "# GOAL: drop the columns that contributed to combination scores\n",
    "\n",
    "# Make lists of the items that comprise scales\n",
    "soc_supp_items = ['w1q164a', 'w1q164b', 'w1q164c', \n",
    "  'w1q164d', 'w1q164e', 'w1q164f', 'w1q164g', 'w1q164h', \n",
    "  'w1q164i', 'w1q164j', 'w1q164k', 'w1q164l']\n",
    "\n",
    "ace_items = ['w1q151', 'w1q152', 'w1q153', \n",
    "  'w1q154', 'w1q155', 'w1q156', 'w1q157', \n",
    "  'w1q158', 'w1q159', 'w1q160', 'w1q161']\n",
    "\n",
    "childhd_gnc_items = [\n",
    "  'w1q147', 'w1q148', 'w1q149', 'w1q150']\n",
    "\n",
    "############# NOT CONDENSED (YET) #############\n",
    "# strain_items = ['w1q146a', 'w1q146b', \n",
    "#   'w1q146c', 'w1q146d', 'w1q146e', 'w1q146f', \n",
    "#   'w1q146g', 'w1q146h', 'w1q146i', 'w1q146j', \n",
    "#   'w1q146k', 'w1q146l']\n",
    "############# NOT CONDENSED (YET) #############\n",
    "\n",
    "daily_discr_items = ['w1q144a', 'w1q144b', \n",
    "  'w1q144c','w1q144d', 'w1q144e', 'w1q144f', \n",
    "  'w1q144g', 'w1q144h', 'w1q144i']\n",
    "\n",
    "# bi_stigma_items = [  # only in wave 2\n",
    "#   'w2q117', 'w2q118', 'w2q119', 'w2q120']\n",
    "\n",
    "int_homo_items = ['w1q128', 'w1q129', \n",
    "  'w1q130', 'w1q131', 'w1q132']\n",
    "\n",
    "felt_stigma_items = ['w1q125', 'w1q126', 'w1q127']\n",
    "\n",
    "drug_items = ['w1q90', 'w1q91', 'w1q92', \n",
    "  'w1q93', 'w1q94', 'w1q95', 'w1q96', \n",
    "  'w1q97', 'w1q98', 'w1q99', 'w1q100']\n",
    "\n",
    "alc_items = ['w1q85', 'w1q86', 'w1q87']\n",
    "\n",
    "ment_dis_items = ['w1q77a', 'w1q77b', \n",
    "  'w1q77c', 'w1q77d', 'w1q77e', 'w1q77f']\n",
    "\n",
    "hc_ster_threat_items = [\n",
    "  'w1q60', 'w1q61', 'w1q62', 'w1q63']\n",
    "\n",
    "comm_conn_items = ['w1q53', 'w1q54', \n",
    "  'w1q55', 'w1q56', 'w1q57', 'w1q58', 'w1q59']\n",
    "\n",
    "lgbis_items = [\n",
    "  'w1q40', 'w1q41', 'w1q42', 'w1q43', 'w1q44']\n",
    "\n",
    "meim_items = [\n",
    "  'w1q21', 'w1q22', 'w1q23', 'w1q24', 'w1q25', 'w1q26']\n",
    "\n",
    "swl_items = [\n",
    "  'w1q186', 'w1q187', 'w1q188', 'w1q189', 'w1q190']\n",
    "\n",
    "swb_items = ['w1q04', 'w1q05', 'w1q06', 'w1q07', \n",
    "  'w1q08', 'w1q09', 'w1q10', 'w1q11', 'w1q12', \n",
    "  'w1q13', 'w1q14', 'w1q15', 'w1q16', 'w1q17', 'w1q18']\n",
    "\n",
    "drop_cols = (soc_supp_items + ace_items + childhd_gnc_items + \n",
    "  daily_discr_items + int_homo_items + felt_stigma_items + \n",
    "  drug_items + alc_items + ment_dis_items + hc_ster_threat_items + \n",
    "  comm_conn_items + lgbis_items + meim_items + swl_items + swb_items)\n",
    "len(drop_cols)\n",
    "\n",
    "meyer.drop(columns = drop_cols, inplace = True)\n",
    "meyer.shape\n",
    "\n",
    "# these are the scales\n",
    "combo_features = ['w1socialwb', 'w1socialwb_i', \n",
    "  'w1lifesat', 'w1lifesat_i', 'w1meim', 'w1meim_i', \n",
    "  'w1idcentral', 'w1idcentral_i', 'w1connectedness',\n",
    "  'w1connectedness_i', 'w1hcthreat', 'w1hcthreat_i', \n",
    "  'w1kessler6', 'w1kessler6_i', 'w1auditc', \n",
    "  'w1auditc_i', 'w1dudit', 'w1dudit_i', 'w1feltstigma', \n",
    "  'w1feltstigma_i', 'w1internalized', 'w1internalized_i', \n",
    "  'w1everyday', 'w1everyday_i', 'w1childgnc', 'w1childgnc_i',\n",
    "  'w1ace', 'w1ace_i', 'w1ace_emo', 'w1ace_emo_i', \n",
    "  'w1ace_inc', 'w1ace_inc_i', 'w1ace_ipv', 'w1ace_ipv_i', \n",
    "  'w1ace_men', 'w1ace_men_i', 'w1ace_phy', 'w1ace_phy_i', \n",
    "  'w1ace_sep', 'w1ace_sep_i', 'w1ace_sex', 'w1ace_sex_i', \n",
    "  'w1ace_sub', 'w1ace_sub_i', 'w1socsupport', \n",
    "  'w1socsupport_fam', 'w1socsupport_fam_i', \n",
    "  'w1socsupport_fr', 'w1socsupport_fr_i', \n",
    "  'w1socsupport_i', 'w1socsupport_so', 'w1socsupport_so_i']\n",
    "\n",
    "# split them up so I can check whether \n",
    "# the _i columns really are free of missing values\n",
    "combo_imputed = [c for c in combo_features if c[-2:]=='_i']\n",
    "combo_not_imputed = [c for c in combo_features if c[-2:]!='_i']\n",
    "\n",
    "# check my splits\n",
    "a = [c for c in combo_imputed if c in combo_not_imputed]\n",
    "b = [c for c in combo_not_imputed if c in combo_imputed]\n",
    "if len(a)==len(b)==0:\n",
    "  print('no overlap')\n",
    "  del (a, b)\n",
    "if (len(combo_imputed)+len(combo_not_imputed))==len(combo_features):\n",
    "  print('all accounted for')\n",
    "  \n",
    "# check for \"missing\" values\n",
    "for i in combo_imputed:\n",
    "  print('')\n",
    "  print(f'{i}, {meyer[i].isna().sum()} NAs')\n",
    "  print(meyer[i].value_counts(dropna = False).sort_values())\n",
    "\n",
    "# see how bad it was in the original\n",
    "for i in combo_not_imputed:\n",
    "  print('')\n",
    "  print(f'{i}, {meyer[i].isna().sum()} NAs')\n",
    "  print(meyer[i].value_counts(dropna = False).sort_values())\n",
    "missing_values = [('w1ace_sex', 75), ('w1ace_phy', 61), \n",
    "  ('w1ace_ipv', 139), ('w1ace_emo', 91), ('w1ace', 277), \n",
    "  ('w1everyday', 40), ('w1dudit', 66), ('w1connectedness', 51), \n",
    "  ('w1socialwb', 59), ('most others', '15-35')]\n",
    "\n",
    "# very grim and not at all surprising that column with the most missings is IPV\n",
    "# (from the ACE survey - so IPV among parents, not participants themselves)\n",
    "# >>> meyer['w1ace_ipv'].value_counts(dropna = False)\n",
    "# w1ace_ipv\n",
    "# 0    950\n",
    "# 1    429\n",
    "#      139\n",
    "# Name: count, dtype: int64\n",
    "# >>> meyer['w1ace_ipv_i'].value_counts(dropna = False)\n",
    "# w1ace_ipv_i\n",
    "# 0    1024\n",
    "# 1     494\n",
    "# Name: count, dtype: int64\n",
    "# >>> 1024-950\n",
    "# 74\n",
    "# >>> 139-74\n",
    "# 65\n",
    "\n",
    "# ok.  their imputation method seems really solid, but that is sus af.\n",
    "# of the people who declined to answer about IPV, you think the majority \n",
    "# of them would have said NO!?!??!??????\n",
    "# I'd be tempted to put every one of those guys down as a yes!!!!\n",
    "# let me see the overlap with other stigmatized stuff\n",
    "len(meyer[(meyer['w1ace_ipv']==' ') & (meyer['w1ace_sex']==' ')])\n",
    "# 30 huh damn I would have thought like all of them\n",
    "# wait.\n",
    "len(meyer[(meyer['w1ace_ipv']=='1') & (meyer['w1ace_sex']==' ')])  # 19\n",
    "len(meyer[(meyer['w1ace_ipv']==' ') & (meyer['w1ace_sex']=='1')])  # 51\n",
    "# ok! that actually lends credibility to their imputation though\n",
    "# if people were too ashamed to admit IPV, they'd probably decline to answer\n",
    "# about CSA too.  these people, at least, really could go either way on IPV.\n",
    "\n",
    "# This is all actually moot \n",
    "# because I don't have a better idea for imputation than what they did.\n",
    "# I think the thing to do, if I can, is to model it on the imputed data\n",
    "# then model it again on the subsample where I've dropped all these NAs\n",
    "# at least the ACE NAs, where there's really a lot.\n",
    "# could also try modeling it just without those columns\n",
    "# a random forest would probably be good, \n",
    "# make sure the whole thing isn't hinging on imputed data\n",
    "# Meyer also probably ran some tests in his paper to make sure this is ok\n",
    "\n",
    "# OK SO.\n",
    "\n",
    "# I've gotta reduce my dimensions\n",
    "# the imputation methods they used seem very reasonable\n",
    "# (see p. 37 of 37166-Documentation-methodology.pdf)\n",
    "# so I'm going to drop the non-imputed ones\n",
    "meyer.drop(columns = combo_not_imputed, inplace = True)\n",
    "meyer.shape  #(1518, 373)\n",
    "\n",
    "# ok!  love that!  let's see what else I can chuck.\n",
    "cols_to_check = [c for c in list(meyer.columns) if c not in combo_imputed]\n",
    "print(cols_to_check)\n",
    "\n",
    "# I am looking thru the documentation and making 2 lists\n",
    "# the variables should ROUGHLY correspond to each other\n",
    "# maybe I'll do some line breaks or whatever.\n",
    "drop_cols_2 = [\n",
    "  'w1q165', 'w1q27', 'w1q28', \n",
    "  'w1q20_1', 'w1q20_2', 'w1q20_3', 'w1q20_4', 'w1q20_5', 'w1q20_6', 'w1q20_7', \n",
    "]\n",
    "\n",
    "keep_cols = [\n",
    "  'w1age', 'cohort', 'w1sex', 'w1gender', 'w1sex_gender', \n",
    "  'screen_race', 'w1race',\n",
    "]\n",
    "\n",
    "check_cols = [\n",
    "  # no age, sex stuff\n",
    "  'w1q20_t_verb', # I suspect this is part of q20 and got rolled into w1race, but I'm not sure off the top of my head\n",
    "]\n",
    "\n",
    "# KEEP GOING ON THESE ON FRIDAY\n",
    "# I JUST FINISHED SEX AND GENDER\n",
    "# PICK UP WITH SEXUAL IDENTITY, PAGE 14 (16) OF THE DOCUMENTATION\n",
    "# 37166-Documentation-methodology.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# not-script 3 in full \n",
    "\\# 2024-05-23_cols_to_check.txt\n",
    "\n",
    "cols_to_check\n",
    "\n",
    "These are the columns that remained after I dropped all the scale items and non-imputed scale features.  What I'm working on now is going through them to try and reduce dimensionality.\n",
    "\n",
    "['studyid', 'waveparticipated', 'w1weight_full', 'w1weight_orig', 'w1cumulative_wt_nr1', 'w1cumulative_wt_nr2', 'w1cumulative_wt_nr3', 'w1cumulative_wt_sampling', 'w1weighting_cell_nr1', 'w1weighting_cell_nr2and3', 'w1frame_wt', 'w1survey_yr', 'geduc1', 'geduc2', 'geducation', 'gemployment2010', 'gmethod_type', 'gmsaname', 'gp1', 'gruca', 'gruca_i', 'gurban', 'gurban_i', 'gzipcode', 'gzipstate', 'gcendiv', 'gcenreg', 'gmilesaway', 'gmilesaway2', 'w1q01', 'w1q02', 'w1q03', 'w1q19a', 'w1q19b', 'w1q19c', 'w1q19d', 'w1q29', 'w1q29_t_verb', 'w1q30_1', 'w1q30_2', 'w1q30_3', 'w1q30_4', 'w1q30_5', 'w1q31a', 'w1q31b', 'w1q31c', 'w1q31d', 'w1q32', 'w1q33', 'w1q34', 'w1q35', 'w1q36', 'w1q37', 'w1q38', 'w1q39_1', 'w1q39_2', 'w1q39_3', 'w1q39_4', 'w1q39_5', 'w1q39_6', 'w1q39_7', 'w1q39_8', 'w1q39_9', 'w1q39_10', 'w1q39_11', 'w1q39_12', 'w1q39_t_verb', 'w1q45', 'w1q46', 'w1q47', 'w1q48', 'w1q49', 'w1q50', 'w1q51', 'w1q52', 'w1q64_1', 'w1q64_2', 'w1q64_3', 'w1q64_4', 'w1q64_5', 'w1q64_6', 'w1q64_7', 'w1q64_8', 'w1q64_9', 'w1q64_10', 'w1q64_11', 'w1q64_12', 'w1q64_13', 'w1q64_t_verb', 'w1q65', 'w1q66_1', 'w1q66_2', 'w1q66_3', 'w1q66_4', 'w1q66_5', 'w1q66_t_verb', 'w1q67', 'w1q68_1', 'w1q68_2', 'w1q68_3', 'w1q69', 'w1q70', 'w1q71', 'w1q72', 'w1q73', 'w1q74_1', 'w1q74_2', 'w1q74_3', 'w1q74_4', 'w1q74_5', 'w1q74_6', 'w1q74_7', 'w1q74_8', 'w1q74_9', 'w1q74_10', 'w1q74_11', 'w1q74_12', 'w1q74_13', 'w1q74_14', 'w1q74_15', 'w1q74_16', 'w1q74_17', 'w1q74_18', 'w1q74_19', 'w1q74_20', 'w1q74_21', 'w1q74_22', 'w1q74_23', 'w1q75', 'w1q76', 'w1q78', 'w1q79', 'w1q80', 'w1q81', 'w1q82', 'w1q83', 'w1q84', 'w1q88', 'w1q89', 'w1q101', 'w1q102', 'w1q103', 'w1q104', 'w1q105', 'w1q106', 'w1q107', 'w1q108', 'w1q109', 'w1q110', 'w1q111', 'w1q112', 'w1q113', 'w1q114', 'w1q115', 'w1q116', 'w1q117', 'w1q118', 'w1q119', 'w1q120', 'w1q121', 'w1q122', 'w1q123a', 'w1q123b', 'w1q123c', 'w1q123d', 'w1q124', 'w1q133', 'w1q133_1', 'w1q133_2', 'w1q133_3', 'w1q134', 'w1q135a', 'w1q135b', 'w1q135c', 'w1q135d', 'w1q135e', 'w1q135f', 'w1q136_1', 'w1q136_2', 'w1q136_3', 'w1q136_4', 'w1q136_5', 'w1q136_6', 'w1q136_7', 'w1q136_8', 'w1q136_9', 'w1q136_10', 'w1q137', 'w1q138', 'w1q139_1', 'w1q139_2', 'w1q139_3', 'w1q139_4', 'w1q139_5', 'w1q139_6', 'w1q139_7', 'w1q139_8', 'w1q139_9', 'w1q139_10', 'w1q140', 'w1q141_1', 'w1q141_2', 'w1q141_3', 'w1q141_4', 'w1q141_5', 'w1q141_6', 'w1q141_7', 'w1q141_8', 'w1q141_9', 'w1q141_10', 'w1q142a', 'w1q142b', 'w1q142c', 'w1q142d', 'w1q142e', 'w1q142f', 'w1q142g', 'w1q142h', 'w1q142i', 'w1q142j', 'w1q142k', 'w1q143_1', 'w1q143_2', 'w1q143_3', 'w1q143_4', 'w1q143_5', 'w1q143_6', 'w1q143_7', 'w1q143_8', 'w1q143_9', 'w1q143_10', 'w1q145_1', 'w1q145_2', 'w1q145_3', 'w1q145_4', 'w1q145_5', 'w1q145_6', 'w1q145_7', 'w1q145_8', 'w1q145_9', 'w1q145_10', 'w1q146a', 'w1q146b', 'w1q146c', 'w1q146d', 'w1q146e', 'w1q146f', 'w1q146g', 'w1q146h', 'w1q146i', 'w1q146j', 'w1q146k', 'w1q146l', 'w1q162', 'w1q163_1', 'w1q163_2', 'w1q163_3', 'w1q163_4', 'w1q163_5', 'w1q163_6', 'w1q163_7', 'w1q163_8', 'w1q163_9', 'w1q163_10', 'w1q166', 'w1q167', 'w1q168', 'w1q169', 'w1q170_1', 'w1q170_2', 'w1q170_3', 'w1q170_4', 'w1q171_1', 'w1q171_2', 'w1q171_3', 'w1q171_4', 'w1q171_5', 'w1q171_6', 'w1q171_7', 'w1q171_8', 'w1q171_9', 'w1q172', 'w1q173', 'w1q174', 'w1q175', 'w1q176', 'w1q177_1', 'w1q177_2', 'w1q177_3', 'w1q177_4', 'w1q177_5', 'w1q177_6', 'w1q177_7', 'w1q177_8', 'w1q177_9', 'w1q177_10', 'w1q177_11', 'w1q177_12', 'w1q178', 'w1q179', 'w1q180', 'w1q181', 'w1q182', 'w1q183', 'w1q184', 'w1q185',  'w1sample',  'w1sexualid', 'w1sexminid', 'w1pinc', 'w1pinc_i', 'w1hinc', 'w1hinc_i', 'w1poverty', 'w1poverty_i', 'w1povertycat', 'w1povertycat_i', 'w1conversion', 'w1conversionhc', 'w1conversionrel', 'gmethod_type_w2', 'grespondent_date_w2', 'gsurvey', 'gmethod_type_w3', 'gp2', 'grace', 'grespondent_date_w3', 'wave3', 'nopolicecontact']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wednesday, May 29, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notes:\n",
    "today I continued cleaning the Meyer dataset.  I finished all the scales that were defined in the documentation, and dropped columns accordingly.  at that point i was down to 337 columns.  I then started going through the 831 page documenation to piece together the rest of what's what.  i started writing a dictionary of how I want to combine these columns, after which I plan to drop most of them.  there are a few I want to keep to see if they perform better alone than they do as a composite, but I want to be careful of introducing too much colinearity.  because I'd really like to be able to do interpretation, I might have to sacrifice some features I think are interesting in order to be able to make sense of the others.\n",
    "\n",
    "I also found a TON of really interesting features that I had to drop just to make sure I have a straightforward enough project to pull off in 2 weeks (left).  I'd love to go back and tinker with them for my portfolio though!\n",
    "\n",
    "files created: \n",
    "- 2024-05-23_AND_2024-05-29_exploring_Meyer_2023_dataset.py\n",
    "- 2024-05-29_cols_to_check.txt\n",
    "- 2024-05-29_notes_about_non-scale_columns.txt\n",
    "both of the first two files are actually just longer versions of the older ones, so most of their contents are redundant.  I used the same setup file as on 5-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script 1 in full: 2024-05-23_AND_2024-05-29_exploring_Meyer_2023_dataset.py\n",
    "\n",
    "# 5/23/24\n",
    "\n",
    "# check out this dataset from Ilan Meyer, my beloved\n",
    "\n",
    "# Import Data\n",
    "meyer = pd.read_csv('./potential_datasets/2024_05_23_download_ICPSR_Meyer_2023_generations_data_attempt_2/ICPSR_37166/DS0007/37166-0007-Data.tsv', sep = '\\t', low_memory=False)\n",
    "meyer.shape #(1518, 1329), but we can cut that down.\n",
    "og_columns = list(meyer.columns)\n",
    "\n",
    "# for RIGHT NOW, I think I'm only going to look at wave 1\n",
    "# the wave stuff is REALLY COOL, but i don't think I understand\n",
    "# time series well enough to get into it for this project\n",
    "# if I get a model working based on wave 1, and write it up\n",
    "# and all that \"good enough,\" then I'll come back and add \n",
    "# some time series stuff\n",
    "# oh it can even just be another phase of the project!\n",
    "# no need to replace anything!  just section B.\n",
    "\n",
    "meyer['WAVEPARTICIPATED'].value_counts(dropna =False)\n",
    "# matches what's in the documentation\n",
    "\n",
    "# ok, so, for now, I am going to drop all the variables marked W2 and W3.  \n",
    "cols = list(meyer.columns)\n",
    "w1_cols = [c for c in cols if c[:2]!='W2']\n",
    "w1_cols = [c for c in w1_cols if c[:2]!='W3']\n",
    "len(w1_cols)\n",
    "\n",
    "# drop columns\n",
    "meyer = meyer[w1_cols]\n",
    "meyer.shape\n",
    "\n",
    "# NAs?\n",
    "meyer.isna().sum().sum()\n",
    "# it says 0, but it's not 0\n",
    "# they must have imputed it with an empty string or something\n",
    "# when I do .value_counts(), a lot of columns have a blank row, e.g.,\n",
    "#                      14\n",
    "# where there absolutely should not be a blank.\n",
    "# so that's fun!  gonna have to clean that up!\n",
    "\n",
    "# i originally thought they only included the base variables\n",
    "# and I would have to compute the scale scores myself, but\n",
    "# OMG THEY DID INCLUDE THE CALC'D SCALES!!!!!!\n",
    "# I JUST COULDN'T FIND THEM BECAUSE ALL CAPS!!\n",
    "\n",
    "meyer.columns = [c.lower() for c in list(meyer.columns)]\n",
    "\n",
    "# GOAL: drop the columns that contributed to combination scores\n",
    "\n",
    "# Make lists of the items that comprise scales\n",
    "soc_supp_items = ['w1q164a', 'w1q164b', 'w1q164c', \n",
    "  'w1q164d', 'w1q164e', 'w1q164f', 'w1q164g', 'w1q164h', \n",
    "  'w1q164i', 'w1q164j', 'w1q164k', 'w1q164l']\n",
    "\n",
    "ace_items = ['w1q151', 'w1q152', 'w1q153', \n",
    "  'w1q154', 'w1q155', 'w1q156', 'w1q157', \n",
    "  'w1q158', 'w1q159', 'w1q160', 'w1q161']\n",
    "\n",
    "childhd_gnc_items = [\n",
    "  'w1q147', 'w1q148', 'w1q149', 'w1q150']\n",
    "\n",
    "############# NOT CONDENSED (YET) #############\n",
    "# strain_items = ['w1q146a', 'w1q146b', \n",
    "#   'w1q146c', 'w1q146d', 'w1q146e', 'w1q146f', \n",
    "#   'w1q146g', 'w1q146h', 'w1q146i', 'w1q146j', \n",
    "#   'w1q146k', 'w1q146l']\n",
    "############# NOT CONDENSED (YET) #############\n",
    "\n",
    "daily_discr_items = ['w1q144a', 'w1q144b', \n",
    "  'w1q144c','w1q144d', 'w1q144e', 'w1q144f', \n",
    "  'w1q144g', 'w1q144h', 'w1q144i']\n",
    "\n",
    "# bi_stigma_items = [  # only in wave 2\n",
    "#   'w2q117', 'w2q118', 'w2q119', 'w2q120']\n",
    "\n",
    "int_homo_items = ['w1q128', 'w1q129', \n",
    "  'w1q130', 'w1q131', 'w1q132']\n",
    "\n",
    "felt_stigma_items = ['w1q125', 'w1q126', 'w1q127']\n",
    "\n",
    "drug_items = ['w1q90', 'w1q91', 'w1q92', \n",
    "  'w1q93', 'w1q94', 'w1q95', 'w1q96', \n",
    "  'w1q97', 'w1q98', 'w1q99', 'w1q100']\n",
    "\n",
    "alc_items = ['w1q85', 'w1q86', 'w1q87']\n",
    "\n",
    "ment_dis_items = ['w1q77a', 'w1q77b', \n",
    "  'w1q77c', 'w1q77d', 'w1q77e', 'w1q77f']\n",
    "\n",
    "hc_ster_threat_items = [\n",
    "  'w1q60', 'w1q61', 'w1q62', 'w1q63']\n",
    "\n",
    "comm_conn_items = ['w1q53', 'w1q54', \n",
    "  'w1q55', 'w1q56', 'w1q57', 'w1q58', 'w1q59']\n",
    "\n",
    "lgbis_items = [\n",
    "  'w1q40', 'w1q41', 'w1q42', 'w1q43', 'w1q44']\n",
    "\n",
    "meim_items = [\n",
    "  'w1q21', 'w1q22', 'w1q23', 'w1q24', 'w1q25', 'w1q26']\n",
    "\n",
    "swl_items = [\n",
    "  'w1q186', 'w1q187', 'w1q188', 'w1q189', 'w1q190']\n",
    "\n",
    "swb_items = ['w1q04', 'w1q05', 'w1q06', 'w1q07', \n",
    "  'w1q08', 'w1q09', 'w1q10', 'w1q11', 'w1q12', \n",
    "  'w1q13', 'w1q14', 'w1q15', 'w1q16', 'w1q17', 'w1q18']\n",
    "\n",
    "drop_cols = (soc_supp_items + ace_items + childhd_gnc_items + \n",
    "  daily_discr_items + int_homo_items + felt_stigma_items + \n",
    "  drug_items + alc_items + ment_dis_items + hc_ster_threat_items + \n",
    "  comm_conn_items + lgbis_items + meim_items + swl_items + swb_items)\n",
    "len(drop_cols)\n",
    "\n",
    "meyer.drop(columns = drop_cols, inplace = True)\n",
    "meyer.shape\n",
    "\n",
    "# these are the scales\n",
    "combo_features = ['w1socialwb', 'w1socialwb_i', \n",
    "  'w1lifesat', 'w1lifesat_i', 'w1meim', 'w1meim_i', \n",
    "  'w1idcentral', 'w1idcentral_i', 'w1connectedness',\n",
    "  'w1connectedness_i', 'w1hcthreat', 'w1hcthreat_i', \n",
    "  'w1kessler6', 'w1kessler6_i', 'w1auditc', \n",
    "  'w1auditc_i', 'w1dudit', 'w1dudit_i', 'w1feltstigma', \n",
    "  'w1feltstigma_i', 'w1internalized', 'w1internalized_i', \n",
    "  'w1everyday', 'w1everyday_i', 'w1childgnc', 'w1childgnc_i',\n",
    "  'w1ace', 'w1ace_i', 'w1ace_emo', 'w1ace_emo_i', \n",
    "  'w1ace_inc', 'w1ace_inc_i', 'w1ace_ipv', 'w1ace_ipv_i', \n",
    "  'w1ace_men', 'w1ace_men_i', 'w1ace_phy', 'w1ace_phy_i', \n",
    "  'w1ace_sep', 'w1ace_sep_i', 'w1ace_sex', 'w1ace_sex_i', \n",
    "  'w1ace_sub', 'w1ace_sub_i', 'w1socsupport', \n",
    "  'w1socsupport_fam', 'w1socsupport_fam_i', \n",
    "  'w1socsupport_fr', 'w1socsupport_fr_i', \n",
    "  'w1socsupport_i', 'w1socsupport_so', 'w1socsupport_so_i']\n",
    "\n",
    "# split them up so I can check whether \n",
    "# the _i columns really are free of missing values\n",
    "combo_imputed = [c for c in combo_features if c[-2:]=='_i']\n",
    "combo_not_imputed = [c for c in combo_features if c[-2:]!='_i']\n",
    "\n",
    "# check my splits\n",
    "a = [c for c in combo_imputed if c in combo_not_imputed]\n",
    "b = [c for c in combo_not_imputed if c in combo_imputed]\n",
    "if len(a)==len(b)==0:\n",
    "  print('no overlap')\n",
    "  del (a, b)\n",
    "if (len(combo_imputed)+len(combo_not_imputed))==len(combo_features):\n",
    "  print('all accounted for')\n",
    "  \n",
    "# check for \"missing\" values\n",
    "for i in combo_imputed:\n",
    "  print('')\n",
    "  print(f'{i}, {meyer[i].isna().sum()} NAs')\n",
    "  print(meyer[i].value_counts(dropna = False).sort_values())\n",
    "\n",
    "# see how bad it was in the original\n",
    "for i in combo_not_imputed:\n",
    "  print('')\n",
    "  print(f'{i}, {meyer[i].isna().sum()} NAs')\n",
    "  print(meyer[i].value_counts(dropna = False).sort_values())\n",
    "missing_values = [('w1ace_sex', 75), ('w1ace_phy', 61), \n",
    "  ('w1ace_ipv', 139), ('w1ace_emo', 91), ('w1ace', 277), \n",
    "  ('w1everyday', 40), ('w1dudit', 66), ('w1connectedness', 51), \n",
    "  ('w1socialwb', 59), ('most others', '15-35')]\n",
    "\n",
    "# very grim and not at all surprising that column with the most missings is IPV\n",
    "# (from the ACE survey - so IPV among parents, not participants themselves)\n",
    "# >>> meyer['w1ace_ipv'].value_counts(dropna = False)\n",
    "# w1ace_ipv\n",
    "# 0    950\n",
    "# 1    429\n",
    "#      139\n",
    "# Name: count, dtype: int64\n",
    "# >>> meyer['w1ace_ipv_i'].value_counts(dropna = False)\n",
    "# w1ace_ipv_i\n",
    "# 0    1024\n",
    "# 1     494\n",
    "# Name: count, dtype: int64\n",
    "# >>> 1024-950\n",
    "# 74\n",
    "# >>> 139-74\n",
    "# 65\n",
    "\n",
    "# ok.  their imputation method seems really solid, but that is sus af.\n",
    "# of the people who declined to answer about IPV, you think the majority \n",
    "# of them would have said NO!?!??!??????\n",
    "# I'd be tempted to put every one of those guys down as a yes!!!!\n",
    "# let me see the overlap with other stigmatized stuff\n",
    "len(meyer[(meyer['w1ace_ipv']==' ') & (meyer['w1ace_sex']==' ')])\n",
    "# 30 huh damn I would have thought like all of them\n",
    "# wait.\n",
    "len(meyer[(meyer['w1ace_ipv']=='1') & (meyer['w1ace_sex']==' ')])  # 19\n",
    "len(meyer[(meyer['w1ace_ipv']==' ') & (meyer['w1ace_sex']=='1')])  # 51\n",
    "# ok! that actually lends credibility to their imputation though\n",
    "# if people were too ashamed to admit IPV, they'd probably decline to answer\n",
    "# about CSA too.  these people, at least, really could go either way on IPV.\n",
    "\n",
    "# This is all actually moot \n",
    "# because I don't have a better idea for imputation than what they did.\n",
    "# I think the thing to do, if I can, is to model it on the imputed data\n",
    "# then model it again on the subsample where I've dropped all these NAs\n",
    "# at least the ACE NAs, where there's really a lot.\n",
    "# could also try modeling it just without those columns\n",
    "# a random forest would probably be good, \n",
    "# make sure the whole thing isn't hinging on imputed data\n",
    "# Meyer also probably ran some tests in his paper to make sure this is ok\n",
    "\n",
    "# OK SO.\n",
    "\n",
    "# I've gotta reduce my dimensions\n",
    "# the imputation methods they used seem very reasonable\n",
    "# (see p. 37 of 37166-Documentation-methodology.pdf)\n",
    "# so I'm going to drop the non-imputed ones\n",
    "meyer.drop(columns = combo_not_imputed, inplace = True)\n",
    "meyer.shape  #(1518, 373)\n",
    "\n",
    "# ok!  love that!  let's see what else I can chuck.\n",
    "cols_to_check = [c for c in list(meyer.columns) if c not in combo_imputed]\n",
    "print(cols_to_check)\n",
    "\n",
    "# I am looking thru the documentation and making 2 lists\n",
    "# the variables should ROUGHLY correspond to each other\n",
    "# maybe I'll do some line breaks or whatever.\n",
    "drop_cols_2 = [\n",
    "  'w1q165', 'w1q27', 'w1q28', \n",
    "  'w1q20_1', 'w1q20_2', 'w1q20_3', 'w1q20_4', 'w1q20_5', 'w1q20_6', 'w1q20_7', \n",
    "  'w1q29', 'w1q29_t_verb', \n",
    "  # kept all ed columns\n",
    "  'gruca', 'gruca_i', 'gurban', 'gzipstate',  'gzipcode', \n",
    "  'w1hinc', 'w1poverty', 'w1povertycat', \n",
    "  'w1q133', 'w1q133_1', 'w1q133_2', 'w1q133_3', \n",
    "  # from here I'm just going thru the 831 page documentation and picking stuff out\n",
    "  'w1weight_orig', \n",
    "  'gmsaname', 'gmethod_type', 'gmethod_type_w2', 'gmethod_type_w3', \n",
    "  'w1cumulative_wt_nr1', 'w1cumulative_wt_nr2', 'w1cumulative_wt_nr3', \n",
    "  'w1cumulative_wt_sampling', 'w1weighting_cell_nr1', 'w1weighting_cell_nr2and3', \n",
    "  'w1frame_wt', \n",
    "]\n",
    "\n",
    "keep_cols = ['studyid', 'waveparticipated', 'w1survey_yr', \n",
    "  'w1age', 'cohort', 'w1sex', 'w1gender', 'w1sex_gender', \n",
    "  'screen_race', 'w1race',\n",
    "  'w1sexualid', 'w1sexminid', \n",
    "  'geduc1', 'geduc2', 'geducation', \n",
    "  'gurban_i', 'gcendiv', 'gcenreg', 'gmilesaway', 'gmilesaway2', \n",
    "  'w1hinc_i', 'w1poverty_i', 'w1povertycat_i', \n",
    "  'w1conversion', 'w1conversionhc', 'w1conversionrel', \n",
    "  'w1weight_full', 'gemployment2010', \n",
    "]\n",
    "\n",
    "check_cols = [\n",
    "  # no age, sex stuff\n",
    "  'w1q20_t_verb', # I suspect this is part of q20 and got rolled into w1race, but I'm not sure off the top of my head\n",
    "]\n",
    "\n",
    "# can I weed out the redacted ones quickly?\n",
    "\n",
    "x = list(meyer.columns)\n",
    "x_redacted = [c for c in x if meyer[c].nunique()==1]\n",
    "# it works!  but I already caught these guys\n",
    "\n",
    "\n",
    "# I finished all the variables that were easy to parse out and assigned\n",
    "# them to a list above.  I am now going to drop the ones that I indicated,\n",
    "# and then I will go through the 831 page documentation to make sense \n",
    "# of what's left and try to drop more.\n",
    "\n",
    "meyer.drop(columns = drop_cols_2, inplace = True) # (1518, 337)\n",
    "\n",
    "suicidal_idea_beh = [\n",
    "  'w1q101', 'w1q102', 'w1q103', 'w1q104', 'w1q105', 'w1q106', 'w1q107', \n",
    "  'w1q108', 'w1q109', 'w1q110', 'w1q111', 'w1q112', 'w1q113', 'w1q114', \n",
    "  'w1q115', 'w1q116', 'w1q117', 'w1q118', 'w1q119', 'w1q120', 'w1q121', \n",
    "]\n",
    "\n",
    "drop_cols_2_again = [\n",
    "  'w1q31a', 'w1q31b', 'w1q31c', 'w1q31d', # redundant with sexual identity\n",
    "  'w1q66_1', 'w1q66_2', 'w1q66_3', 'w1q66_4', 'w1q66_5', 'w1q66_t_verb', # interesting to compare \n",
    "  #ER to Dr ofc, but not for this study.  too many columns already ^\n",
    "  'w1q67', 'w1q68_1', 'w1q68_2', 'w1q68_3', 'w1q70', 'w1q71', 'w1q73', # <- same ^ and V\n",
    "  'w1q74_1', 'w1q74_2', 'w1q74_3', 'w1q74_4', 'w1q74_7', 'w1q74_8', 'w1q74_9', \n",
    "  'w1q74_12', 'w1q74_13', 'w1q74_15', 'w1q74_16', 'w1q74_19', 'w1q80', 'w1q81',\n",
    "  'w1q82', 'w1q83', 'w1q84', 'w1q88', 'w1q118', \n",
    "]\n",
    "\n",
    "keep_cols_good_on_own = [\n",
    "  'w1q01', 'w1q02', 'w1q03', 'w1q32', 'w1q33', 'w1q34', 'w1q35', 'w1q36', \n",
    "  'w1q37', 'w1q38', 'w1q52', 'w1q65', 'w1q69', 'w1q72', 'w1q74_21', \n",
    "  'w1q74_22', 'w1q74_23', 'w1q78', 'w1q79', 'w1q89', 'w1q119', 'w1q134', \n",
    "  'w1q136_7', 'w1q139_7', 'w1q140', 'w1q141_7', \n",
    "]\n",
    "\n",
    "keep_cols_ohe_done = [\n",
    "  'w1q30_1', 'w1q30_2', 'w1q30_3', 'w1q30_4', 'w1q30_5', \n",
    "  'w1q39_1', 'w1q39_2', 'w1q39_3', 'w1q39_4', 'w1q39_5', 'w1q39_6', 'w1q39_7', \n",
    "  'w1q39_8', 'w1q39_9', 'w1q39_10', 'w1q39_11', 'w1q39_12', 'w1q39_t_verb',\n",
    "]\n",
    "\n",
    "# manually combine columns in ways that *I* think make sense\n",
    "# here I am creating a dictionary where the keys are the new column names I want\n",
    "# and the values are lists, wherein the first value on the list is the method \n",
    "# of combination, and the remainder are the columns to be combined\n",
    "# if the method is 'recode', then I probably need to give it more direct attn\n",
    "# but all the others I am hoping to be able to automate\n",
    "# the end goal is to use this dictionary to either generate or directly run\n",
    "# the code to create the new columns and drop the ones no longer needed\n",
    "# before dropping the columns, I should check them against keep_cols\n",
    "# to make sure I'm not hoping to keep them individually in addition to combo'ing\n",
    "\n",
    "feat_eng_dict = {\n",
    "  'pers_well_being': ['sum', 'w1q01', 'w1q02', ],\n",
    "  'neighb_welcoming': ['mean', 'w1q19a', 'w1q19b', 'w1q19c', 'w1q19d', ],\n",
    "  'age_awakening': ['min','w1q45', 'w1q46', 'w1q47', 'w1q48', ],\n",
    "  'age_out': ['min', 'w1q49', 'w1q50', 'w1q51', ]\n",
    "  'health_insurance': ['binarize', 'w1q64_1', 'w1q64_2', 'w1q64_3', 'w1q64_4', \n",
    "    'w1q64_5', 'w1q64_6', 'w1q64_7', 'w1q64_8', 'w1q64_9', 'w1q64_10', \n",
    "    'w1q64_11', 'w1q64_12', 'w1q64_13', 'w1q64_t_verb', ], \n",
    "  'serious_health_cond': ['binarize', 'w1q74_5', 'w1q74_6', 'w1q74_10', \n",
    "    'w1q74_11', 'w1q74_14', 'w1q74_17', 'w1q74_18', 'w1q74_20', ], \n",
    "  'disabled': ['binarize', 'w1q75', 'w1q76', ],\n",
    "  'suicidal_ideation': ['sum', 'w1q101', 'w1q105', 'w1q109', ], \n",
    "  'suicide_attempts': ['recode', 'w1q113', 'w1q114', ],\n",
    "  'sui_idea_age_first': ['min', 'w1q102', 'w1q103', 'w1q104', \n",
    "    'w1q106', 'w1q107', 'w1q108', 'w1q110', 'w1q111', 'w1q112', ],\n",
    "  'sui_idea_age_recent': ['max', 'w1q102', 'w1q103', 'w1q104', \n",
    "    'w1q106', 'w1q107', 'w1q108', 'w1q110', 'w1q111', 'w1q112', ],\n",
    "  'sui_attem_age_first': ['min', 'w1q115', 'w1q116', 'w1q117', ], \n",
    "  'sui_attem_age_recent': ['max', 'w1q115', 'w1q116', 'w1q117', ], \n",
    "  'nssh_age_first': ['min', 'w1q120', 'w1q121', 'w1q122', ],\n",
    "  'nssh_age_recent': ['max', 'w1q120', 'w1q121', 'w1q122', ],\n",
    "  'outness': ['sum', 'w1q123a', 'w1q123b', 'w1q123c', 'w1q123d', 'w1q124', ],\n",
    "  \n",
    "  'abusive_treatment': ['sum', 'w1q135a', 'w1q135b', \n",
    "    'w1q135c', 'w1q135d', 'w1q135e', 'w1q135f', ],\n",
    "  'work_neg_outcomes': ['recode', 'w1q137', 'w1q138', ], # account for age\n",
    "  \n",
    "  'abus_treat_non_queer': ['binarize', 'w1q136_1', 'w1q136_5', 'w1q136_6', \n",
    "    'w1q136_8', 'w1q136_9', 'w1q136_10', ],\n",
    "  'work_disc_non_queer': ['binarize', 'w1q139_1', 'w1q139_5', 'w1q139_6', \n",
    "    'w1q139_8', 'w1q139_9', 'w1q139_10', ],\n",
    "  'housing_disc_non_queer': ['binarize', 'w1q141_1', 'w1q141_5', 'w1q141_6', \n",
    "    'w1q141_8', 'w1q141_9', 'w1q141_10', ]\n",
    "  \n",
    "  'abus_treat_sex_gender': ['binarize', 'w1q136_2', 'w1q136_3', 'w1q136_4', ],\n",
    "  'work_disc_sex_gender': ['binarize', 'w1q139_2', 'w1q139_3', 'w1q139_4', ],\n",
    "  'housing_disc_sex_gender': ['binarize', \n",
    "    'w1q141_2', 'w1q141_3', 'w1q141_4', ]\n",
    "  \n",
    "  \n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# script 2 in full: 2024-05-29_cols_to_check.txt\n",
    "\n",
    "cols_to_check\n",
    "\n",
    "These are the columns that remained after I dropped all the scale items and non-imputed scale features.  What I'm working on now is going through them to try and reduce dimensionality.\n",
    "\n",
    "THIS IS A CONTINUATION OF THE PREVIOUS DOC BY THE SAME NAME\n",
    "\n",
    "['gp1',  'w1q142a', 'w1q142b', 'w1q142c', 'w1q142d', 'w1q142e', 'w1q142f', 'w1q142g', 'w1q142h', 'w1q142i', 'w1q142j', 'w1q142k', 'w1q143_1', 'w1q143_2', 'w1q143_3', 'w1q143_4', 'w1q143_5', 'w1q143_6', 'w1q143_7', 'w1q143_8', 'w1q143_9', 'w1q143_10', 'w1q145_1', 'w1q145_2', 'w1q145_3', 'w1q145_4', 'w1q145_5', 'w1q145_6', 'w1q145_7', 'w1q145_8', 'w1q145_9', 'w1q145_10', 'w1q146a', 'w1q146b', 'w1q146c', 'w1q146d', 'w1q146e', 'w1q146f', 'w1q146g', 'w1q146h', 'w1q146i', 'w1q146j', 'w1q146k', 'w1q146l', 'w1q162', 'w1q163_1', 'w1q163_2', 'w1q163_3', 'w1q163_4', 'w1q163_5', 'w1q163_6', 'w1q163_7', 'w1q163_8', 'w1q163_9', 'w1q163_10', 'w1q166', 'w1q167', 'w1q168', 'w1q169', 'w1q170_1', 'w1q170_2', 'w1q170_3', 'w1q170_4', 'w1q171_1', 'w1q171_2', 'w1q171_3', 'w1q171_4', 'w1q171_5', 'w1q171_6', 'w1q171_7', 'w1q171_8', 'w1q171_9', 'w1q172', 'w1q173', 'w1q174', 'w1q175', 'w1q176', 'w1q177_1', 'w1q177_2', 'w1q177_3', 'w1q177_4', 'w1q177_5', 'w1q177_6', 'w1q177_7', 'w1q177_8', 'w1q177_9', 'w1q177_10', 'w1q177_11', 'w1q177_12', 'w1q178', 'w1q179', 'w1q180', 'w1q181', 'w1q182', 'w1q183', 'w1q184', 'w1q185',  'w1sample',  'w1pinc', 'w1pinc_i', 'grespondent_date_w2', 'gsurvey', 'gp2', 'grace', 'grespondent_date_w3', 'wave3', 'nopolicecontact']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# script 3 in full: 2024-05-29_notes_about_non-scale_columns.txt\n",
    "\n",
    "notes about non-scale columns\n",
    "\n",
    "- for right now I've kept the current well being and the future predicted well being columns, because I think it could be interesting to see if predicting higher or lower than current correlates with anything.  I've also made instructions to combine them (higher is better, regardless fo hether it's current WB or optimism for future WB), which may end up being more parsimonious.\n",
    "- I've also kept Q3, which is about happiness, but I suspect it's very corr'd with WB.  check that, and then either combine or drop it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notes:\n",
    "\n",
    "\n",
    "files created: \n",
    "- x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script 1 in full:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
