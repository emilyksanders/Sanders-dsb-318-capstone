{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thursday, May 23, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think the thing to do, if I can, is to model it on the imputed data\n",
    "# then model it again on the subsample where I've dropped all these NAs\n",
    "# at least the ACE NAs, where there's really a lot.\n",
    "# could also try modeling it just without those columns\n",
    "# a random forest would probably be good, \n",
    "# make sure the whole thing isn't hinging on imputed data\n",
    "# Meyer also probably ran some tests in his paper to make sure this is ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also found a TON of really interesting features that I had to drop just to make sure I have a straightforward enough project to pull off in 2 weeks (left).  I'd love to go back and tinker with them for my portfolio though!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# script 3 in full: 2024-05-29_notes_about_non-scale_columns.txt\n",
    "\n",
    "notes about non-scale columns\n",
    "\n",
    "- for right now I've kept the current well being and the future predicted well being columns, because I think it could be interesting to see if predicting higher or lower than current correlates with anything.  I've also made instructions to combine them (higher is better, regardless fo hether it's current WB or optimism for future WB), which may end up being more parsimonious.\n",
    "- I've also kept Q3, which is about happiness, but I suspect it's very corr'd with WB.  check that, and then either combine or drop it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monday, June 3, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Friends of gmilesaway2\n",
    "# It's actually not a very good assumption that they live\n",
    "# more than 60 miles away. 73.5% of people live w/i 60m!\n",
    "# And yet, most people have never gone.  \n",
    "# I think the thing to impute here is a 0 under the original \n",
    "# meaning, that is, within 60 miles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wednesday, June 5, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think when this is all over, I should reload a clean, fresh copy of the dataframe and see\n",
    "- how many NAs there are per ROW -- I wonder if there are a handful of people who skipped a lot of questions and I've ended up imputing basically their whole row\n",
    "- how many cells I've altered.  it all seems so reasonable when I'm going one column at a time, but when I step back and watch every single column turn into an _ei column, it makes me wonder if I'm destroying my dataset.  If the final tally is staggering, then I should probably go with Hank's suggestion of only picking an handful of columns and ignoring the rest.\n",
    "\n",
    "In any case, today I finished doing the imputation as laid out in imputation_plan.xlsx.  Or, mostly.  I changed my mind on a few things as I went, and discovered things along the way.  Most memorably, some column that I meant to impute with the median populated value ended up just being 0s, because once I converted the 97s to 0s, that was the median.  I'm sure there's a way to tell SI to impute only from values in a range, but 0 was faster.  I also cleaned up a bunch more of those 97s et al., and did some subset investigations.  On some poverty and employment measures there were probably more columns that I could have used to predict the missing values, but using measures of central tendency or just the columns that came most readily to mind was fastest, and will have to do for this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUT because I imputed the 97s to be 0s, and there were so many 97s, that made the \n",
    "# median and mode 0.  So most of these guys just ended up imputed with 0s.\n",
    "# It's not exactly what I wanted (the true missings are people who DID have the \n",
    "# relevant thoughts, but just wouldn't say when), but given that there are so few \n",
    "# true missings, and that this has already eaten up a ton of time, I think it'll\n",
    "# be fine to leave for this iteration.  Put it in the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thursday, June 6, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I discovered that the kessler values *are not normally distributed*.**  I tried a few different things, and taking the square root of them showed the most improvement, although the qqplot still looks not-great (not as bad as project 4 though!).  **I created a column for the square root of these values, but *did not delete the original values*.  It will be important to not include them, or the `studyid` in my X matrix!**\n",
    "\n",
    "All of the non-NA NAs were handled a little differently, but (I think) I sufficiently commented the code to explain what I did and why.  Where possible/necessary/I remembered, I tried to mirror what I did with the actual NAs when dealing with these values.\n",
    "\n",
    "I then went through all the columns indicated in my `feat_eng_dict`, and recoded or transformed them as necessary.  I also updated the names of the columns in the dictionary, because all but literally 1 of them have had `'_ei'` and sometimes `'_r'` tacked onto them by now.  What I did with each batch of columns is marked in comments in the code.  This is also the script where I defined and used a function.  Also in this script, I OHE'd the columns about what religion someone was raised in or practices now.  I first collapsed these categories into fewer bins, then OHE'd them.  I chose to drop the resulting column that corresponded to, more or less, \"not religious,\" because it seemed most intuitive.  The other 2 categories are for Christian-ish religions, and other.  Despite it being somewhat disrespectful, I chose to collapse all other religious practices into \"other\" because these categories were all so small on their own.  Even combined, they are dwarfed by the other two options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### script 3 in full:\n",
    "2024-06-06_y-variable.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thursday, June 6, 2024\n",
    "\n",
    "# I should probably also choose a y variable.  [several hours latere]  Let's go with\n",
    "# Kessler6!  It's a general mental health scale.  \n",
    "\n",
    "# Ok, I'll square root it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### script 4 in full:\n",
    "2024-06-06_column_recoding_for_feat_eng_dict_combinations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composite Scale Calculations\n",
    "\n",
    "# In this script, I need to go back to `feat_eng_dict`, that list I made in \n",
    "# `2024-05-23_thru_2024-05-30_exploring_Meyer_2023_dataset.py`, and use it to \n",
    "# combine some of these columns into composite columns and drop the rest.\n",
    "\n",
    "\n",
    "\n",
    "# religiosity \n",
    "\n",
    "# here's what 179 is now; 1 and 2 are massive in 180\n",
    "# 1 Protestant (for example, Baptist, Methodist) 295 19.4 %\n",
    "# 2 Roman Catholic 133 8.8 %\n",
    "# 3 Mormon (Church of Jesus Christ of Latter-day Saints or LDS) 10 0.7 %\n",
    "# 4 Orthodox (Greek, Russian, or another Orthodox church) 6 0.4 %\n",
    "\n",
    "# 5 Jewish 38 2.5 %\n",
    "# 6 Muslim 3 0.2 %\n",
    "# 7 Buddhist 30 2.0 %\n",
    "# 8 Hindu 1 0.1 %\n",
    "# 11 Spiritual 262 17.3 %\n",
    "# 12 Something else 95 6.3 %\n",
    "\n",
    "# 9 Atheist (do not believe in God) 192 12.6 %\n",
    "# 10 Agnostic (not sure if there is a God) 156 10.3 %\n",
    "# 13 Nothing in particular 273 18.0 %\n",
    "\n",
    "# collapse 3-8 into \"other organized\"\n",
    "# .... actually collapse more, bcz this needs to be OHE'd\n",
    "\n",
    "# 1-4 christian-influenced religious     1\n",
    "# 5-8, 11-12  non-christian religious    5\n",
    "# 9-10, 13 not religious                 make this 0, because it's literally none\n",
    "\n",
    "\n",
    "\n",
    "# I actually cannot think of a meaningful way to combine these.I think the \n",
    "# thing to do is just leave them all in alone, then see what pops as meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Friday, June 7, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today I finally got to run my `feat_eng_dict`!  I made some changes to it, and just summed up a lot of the things I was originally going to binarize.  I wanted to get a good look at them to see if there were differences based on the extent to which whatever the thing is has happened to someone, and in a handful of cases there were, but for the most part I think I would have been better off binarizing them.  I will try to do that in the future.  **Throughout the course of this evening, I have been thinking that I have to treat all of these columns the same way.  At this moment, I no longer think that's true.**  I think it's probably fine to say, \"I looked at these guys, and some of them had magnitude effects and some of them didn't.  I binarized the ones that didn't, and kept the others.\"\n",
    "\n",
    "I then conducted some exploratory data analysis, mostly through the production of graphs.  These graphs can be found in the images folder.  In addition to the frequency distributions of each variable and their relationship (shown through scatterplots) with the target variable, I also created qqplots for each variable, and for 3 transformed versions of each variable.  The purpose of this was to assess each variable's normality, and determine whether any of them would benefit from a linear transformation.  I ultimately decided that this was not likely to useful for any variable other than the target, which is the square root of the Kessler scores.\n",
    "\n",
    "Look at these plots also revealed a number of variables that still need to be one-hot encoded, 0-based, or otherwise modified.  I would also like to rename the columns to be more intuitive, so that I don't have to contiually refer to the documentation.  I opted not to do all that before running my first model, but it would be good to do it before including any of those variables in the model.  I started several lists to do these cleaning tasks, but did not finish any of them.  These lists can be found in `2024-06-07-eda.py`, `2024-06-07_NEW_feat_eng_dict.py`, and `2024-06-07_columns-i-want-to-screw-with-some-more-and-how.py`.  When I have time to address these cleaning issues, I intend to rename and modify these scripts.\n",
    "\n",
    "Finally, I created my first model!  I flipped through the scatterplots and just eyeballed some predictors that seemed reasonable, and put them all into a linear regression.  I conducted a train-test split for a little bit of a check on the model, to get a sense of how overfit it might be, but I kept the test size small because this model is mostly for inference.  I am not concerned about its applicability to new data in the future, because newer data is likely to be legitimately different than this data from 2016.  I do, however, want to keep an eye on overfitting, especially as I add more predictors to my model.  Dimensionality has been a concern throughout this entire process, and I am wary of allowing my model to coil itself too tightly around the data.  Although I am not concerned about this model generalizing perfectly to future data, I also do not want it to be so bespoke to the current data that it becomes unsuitable for interpretation.  In other words, if it becomes so overfit that it cannot even generalize to testing data from the same dataset, then its coefficients are unlikely to be meaningful for any level of analysis.\n",
    "\n",
    "I did some cross validation because it seemed like a good idea to demonstrate that I know how to do that, although without gridsearching over anything, I'm not sure it's really necessary.\n",
    "\n",
    "I used several metrics to evaluate my model, and I think it's a decent model for the area.  $R^2$ was around 0.6 for both training and testing, and all of the loss functions were <1.  (This makes sense, because the y-variable itself is a square root.  Squaring a float <1 will make it smaller, not larger.)  This implies that my model is usually within a range of +/-1 with its predictions of the square root of Kessler scores (range: 0-4.9), and within +/-0.5 for the re-squared values (range: 0-24).\n",
    "\n",
    "I honestly can't believe how good this thing is for being so quickly slapped together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### script 4 in full:\n",
    "4. 2024-06-07-eda.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Friday, June 7, 2024\n",
    "# EDA\n",
    "\n",
    "# As usual, we're starting with my beloved autoplots - now with new arguments!\n",
    "\n",
    "autoplots(meyer, 'w1kessler6_i', qqplots=True, transform=True, line=False, verbose=True)\n",
    "autoplots(meyer, 'kessler6_sqrt', qqplots=True, transform=True, line=False, verbose=True)\n",
    "\n",
    "# There are a few more that I need to OHE, 0-base, or otherwise tinker with, but I'm going\n",
    "# to try to resist the urge to do that until I have SOME kind of model fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### script 5 in full:\n",
    "5. 2024-06-07_NEW_feat_eng_dict.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thursday, June 7, 2024\n",
    "# NEW feat_eng_dict\n",
    "\n",
    "# I thought I was so smart before, just getting a sum from these guys.\n",
    "# Fool.  It dilutes the power of the \"yes\"s! There aren't enough \"yes\"s \n",
    "# in any one level of frequency to compete with the \"no\"s.\n",
    "\n",
    "# these are some visually very promising ones\n",
    "good_ones = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### script 7 in full:\n",
    "7. 2024-06-07_modeling-part-1.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Friday, June 7, 2024\n",
    "# Modeling!\n",
    "\n",
    "\n",
    "# I'm just going to eyeball some features from the scatterplots\n",
    "good_ones = ['chronic_strain', 'suicidality', 'w1age', 'w1auditc_i', \n",
    "    'w1connectedness_i', 'w1conversion', 'w1dudit_i', 'w1everyday_i', \n",
    "  'w1feltstigma_i', 'w1idcentral_i', 'w1internalized_i', 'w1lifesat_i', \n",
    "  'w1meim_i', 'w1pinc_i', 'w1poverty_i_ei', 'w1q03_ei', 'w1q33_ei', \n",
    "  'w1q52_ei', 'w1q72_ei', 'w1q74_22_ei', 'w1q74_21_ei', 'w1q140_ei', \n",
    "  'w1q166_ei', 'w1q167_ei', 'w1q171_8_ei', 'w1q181_ei_r', 'w1socialwb_i', \n",
    "  'w1socsupport_i']\n",
    "\n",
    "# Very small testing set because this is an inferential model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
